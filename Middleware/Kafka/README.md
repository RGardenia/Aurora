# Kafka



â€‹	Kafkaæ˜¯ ä¸€ä¸ªå¼€æºçš„ åˆ†å¸ƒå¼äº‹ä»¶æµå¹³å° ï¼ˆEvent Streaming Platformï¼‰ï¼Œè¢«æ•°åƒå®¶å…¬å¸ç”¨äºé«˜æ€§èƒ½æ•°æ®ç®¡é“ã€æµåˆ†æã€æ•°æ®é›†æˆå’Œå…³é”®ä»»åŠ¡åº”ç”¨

> â€‹	æ¶ˆæ¯é˜Ÿåˆ— ä¼ä¸šä¸­æ¯”è¾ƒå¸¸è§çš„æ¶ˆæ¯é˜Ÿåˆ—äº§å“ä¸»è¦æœ‰Kafkaã€ActiveMQ ã€RabbitMQ ã€ RocketMQ ç­‰ã€‚ åœ¨å¤§æ•°æ®åœºæ™¯ä¸»è¦é‡‡ç”¨ Kafka ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—ã€‚åœ¨ JavaEE å¼€å‘ä¸­ä¸»è¦é‡‡ç”¨ ActiveMQã€ RabbitMQã€RocketMQ

**åº”ç”¨åœºæ™¯**

ä¼ ç»Ÿçš„æ¶ˆæ¯é˜Ÿåˆ—çš„ä¸»è¦åº”ç”¨åœºæ™¯åŒ…æ‹¬ï¼šç¼“å­˜/æ¶ˆå³°ã€è§£è€¦å’Œå¼‚æ­¥é€šä¿¡

- ç¼“å†²/æ¶ˆå³°ï¼šæœ‰åŠ©äºæ§åˆ¶å’Œä¼˜åŒ–æ•°æ®æµç»è¿‡ç³»ç»Ÿçš„é€Ÿåº¦ï¼Œè§£å†³ç”Ÿäº§æ¶ˆæ¯å’Œæ¶ˆè´¹æ¶ˆæ¯çš„å¤„ç†é€Ÿåº¦ä¸ä¸€è‡´çš„æƒ…å†µ
- è§£è€¦ï¼šå…è®¸ä½ ç‹¬ç«‹çš„æ‰©å±•æˆ–ä¿®æ”¹ä¸¤è¾¹çš„å¤„ç†è¿‡ç¨‹ï¼Œåªè¦ç¡®ä¿å®ƒä»¬éµå®ˆåŒæ ·çš„æ¥å£çº¦æŸ
- å¼‚æ­¥é€šä¿¡ï¼šå…è®¸ç”¨æˆ·æŠŠä¸€ä¸ªæ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—ï¼Œä½†å¹¶ä¸ç«‹å³å¤„ç†å®ƒï¼Œç„¶ååœ¨éœ€è¦çš„æ—¶å€™å†å»å¤„ç†å®ƒä»¬

<img src="images/image-20231010222304502.png" alt="image-20231010222304502" style="zoom:67%;" />

**æ¶ˆæ¯é˜Ÿåˆ—çš„ä¸¤ç§æ¨¡å¼**

1ï¼‰ç‚¹å¯¹ç‚¹æ¨¡å¼ï¼šæ¶ˆè´¹è€…ä¸»åŠ¨æ‹‰å–æ•°æ®ï¼Œæ¶ˆæ¯æ”¶åˆ°åæ¸…é™¤æ¶ˆæ¯

<img src="images/image-20231010225931253.png" alt="image-20231010225931253" style="zoom:80%;" />

2ï¼‰å‘å¸ƒ/è®¢é˜…æ¨¡å¼

- å¯ä»¥æœ‰å¤šä¸ªtopicä¸»é¢˜ï¼ˆæµè§ˆã€ç‚¹èµã€æ”¶è—ã€è¯„è®ºç­‰ï¼‰
- æ¶ˆè´¹è€…æ¶ˆè´¹æ•°æ®ä¹‹åï¼Œä¸åˆ é™¤æ•°æ®
- æ¯ä¸ªæ¶ˆè´¹è€…ç›¸äº’ç‹¬ç«‹ï¼Œéƒ½å¯ä»¥æ¶ˆè´¹åˆ°æ•°æ®

![image-20231010230026046](images/image-20231010230026046.png)

## **Kafka åŸºç¡€æ¶æ„**

1. ä¸ºæ–¹ä¾¿æ‰©å±•ï¼Œå¹¶æé«˜ååé‡ï¼Œä¸€ä¸ª topic åˆ†ä¸ºå¤šä¸ª partition
2. .é…åˆåˆ†åŒºçš„è®¾è®¡ï¼Œæå‡ºæ¶ˆè´¹è€…ç»„çš„æ¦‚å¿µï¼Œç»„å†…æ¯ä¸ªæ¶ˆè´¹è€…å¹¶è¡Œæ¶ˆè´¹
3. ä¸ºæé«˜å¯ç”¨æ€§ï¼Œä¸ºæ¯ä¸ª partition å¢åŠ è‹¥å¹²å‰¯æœ¬ï¼Œç±»ä¼¼NameNode HA
4. ZK ä¸­è®°å½•è°æ˜¯ leaderï¼ŒKafka2.8.0 ä»¥åä¹Ÿå¯ä»¥é…ç½®ä¸é‡‡ç”¨ ZK

<img src="images/image-20231010230342102.png" alt="image-20231010230342102" style="zoom:80%;" />

ï¼ˆ1ï¼‰Producerï¼šæ¶ˆæ¯ç”Ÿäº§è€…ï¼Œå°±æ˜¯å‘ Kafka broker å‘æ¶ˆæ¯çš„å®¢æˆ·ç«¯ã€‚ 
ï¼ˆ2ï¼‰Consumerï¼šæ¶ˆæ¯æ¶ˆè´¹è€…ï¼Œå‘ Kafka broker å–æ¶ˆæ¯çš„å®¢æˆ·ç«¯ã€‚ 
ï¼ˆ3ï¼‰Consumer Groupï¼ˆCGï¼‰ï¼šæ¶ˆè´¹è€…ç»„ï¼Œç”±å¤šä¸ª consumer ç»„æˆã€‚æ¶ˆè´¹è€…ç»„å†…æ¯ä¸ªæ¶ˆ è´¹è€…è´Ÿè´£æ¶ˆè´¹ä¸åŒåˆ†åŒºçš„æ•°æ®ï¼Œä¸€ä¸ªåˆ†åŒºåªèƒ½ç”±ä¸€ä¸ªç»„å†…æ¶ˆè´¹è€…æ¶ˆè´¹ï¼›æ¶ˆè´¹è€…ç»„ä¹‹é—´äº’ä¸ å½±å“ã€‚æ‰€æœ‰çš„æ¶ˆè´¹è€…éƒ½å±äºæŸä¸ªæ¶ˆè´¹è€…ç»„ï¼Œå³æ¶ˆè´¹è€…ç»„æ˜¯é€»è¾‘ä¸Šçš„ä¸€ä¸ªè®¢é˜…è€…ã€‚
ï¼ˆ4ï¼‰Brokerï¼šä¸€å° Kafka æœåŠ¡å™¨å°±æ˜¯ä¸€ä¸ª brokerã€‚ä¸€ä¸ªé›†ç¾¤ç”±å¤šä¸ª broker ç»„æˆã€‚ä¸€ä¸ª broker å¯ä»¥å®¹çº³å¤šä¸ª topicã€‚
ï¼ˆ5ï¼‰Topicï¼šå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªé˜Ÿåˆ—ï¼Œç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…é¢å‘çš„éƒ½æ˜¯ä¸€ä¸ª topicã€‚ 
ï¼ˆ6ï¼‰Partitionï¼šä¸ºäº†å®ç°æ‰©å±•æ€§ï¼Œä¸€ä¸ªéå¸¸å¤§çš„ topic å¯ä»¥åˆ†å¸ƒåˆ°å¤šä¸ª brokerï¼ˆå³æœ åŠ¡å™¨ï¼‰ä¸Šï¼Œä¸€ä¸ª topic å¯ä»¥åˆ†ä¸ºå¤šä¸ª partitionï¼Œæ¯ä¸ª partition æ˜¯ä¸€ä¸ªæœ‰åºçš„é˜Ÿåˆ—ã€‚ 
ï¼ˆ7ï¼‰Replicaï¼šå‰¯æœ¬ã€‚ä¸€ä¸ª topic çš„æ¯ä¸ªåˆ†åŒºéƒ½æœ‰è‹¥å¹²ä¸ªå‰¯æœ¬ï¼Œä¸€ä¸ª Leader å’Œè‹¥å¹²ä¸ª Followerã€‚ 
ï¼ˆ8ï¼‰Leaderï¼šæ¯ä¸ªåˆ†åŒºå¤šä¸ªå‰¯æœ¬çš„â€œä¸»â€ï¼Œç”Ÿäº§è€…å‘é€æ•°æ®çš„å¯¹è±¡ï¼Œä»¥åŠæ¶ˆè´¹è€…æ¶ˆè´¹æ•° æ®çš„å¯¹è±¡éƒ½æ˜¯ Leaderã€‚ 
ï¼ˆ9ï¼‰Followerï¼šæ¯ä¸ªåˆ†åŒºå¤šä¸ªå‰¯æœ¬ä¸­çš„â€œä»â€ï¼Œå®æ—¶ä» Leader ä¸­åŒæ­¥æ•°æ®ï¼Œä¿æŒå’Œ Leader æ•°æ®çš„åŒæ­¥ã€‚Leader å‘ç”Ÿæ•…éšœæ—¶ï¼ŒæŸä¸ª Follower ä¼šæˆä¸ºæ–°çš„ Leaderã€‚



## éƒ¨ç½²

### é›†ç¾¤è§„åˆ’

| hadoop001 | hadoop002 | hadoop003 |
| :-------: | :-------: | :-------: |
|    zk     |    zk     |    zk     |
|   kafka   |   kafka   |   kafka   |



### å®‰è£…

0ï¼‰å®˜æ–¹ä¸‹è½½åœ°å€ï¼šhttp://kafka.apache.org/downloads.html

1ï¼‰è§£å‹å®‰è£…åŒ…

```bash
mkdir /opt/module
tar -zxvf kafka_2.12-3.6.0.tgz -C /opt/module/
mv kafka_2.12-3.6.0 kafka
```

2ï¼‰è¿›å…¥åˆ° `/opt/module/kafka` ç›®å½•ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶

```bash
cd config/
vim server.properties
### è¾“å…¥ä»¥ä¸‹å†…å®¹
#broker çš„å…¨å±€å”¯ä¸€ç¼–å·ï¼Œä¸èƒ½é‡å¤ï¼Œåªèƒ½æ˜¯æ•°å­—
broker.id=0
#å¤„ç†ç½‘ç»œè¯·æ±‚çš„çº¿ç¨‹æ•°é‡
num.network.threads=3
#ç”¨æ¥å¤„ç†ç£ç›˜ IO çš„çº¿ç¨‹æ•°é‡
num.io.threads=8
#å‘é€å¥—æ¥å­—çš„ç¼“å†²åŒºå¤§å°
socket.send.buffer.bytes=102400
#æ¥æ”¶å¥—æ¥å­—çš„ç¼“å†²åŒºå¤§å°
socket.receive.buffer.bytes=102400
#è¯·æ±‚å¥—æ¥å­—çš„ç¼“å†²åŒºå¤§å°
socket.request.max.bytes=104857600
#kafka è¿è¡Œæ—¥å¿—(æ•°æ®)å­˜æ”¾çš„è·¯å¾„ï¼Œè·¯å¾„ä¸éœ€è¦æå‰åˆ›å»ºï¼Œkafka è‡ªåŠ¨å¸®ä½ åˆ›å»ºï¼Œå¯ä»¥é…ç½®å¤šä¸ªç£ç›˜è·¯å¾„ï¼Œè·¯å¾„ä¸è·¯å¾„ä¹‹é—´å¯ä»¥ç”¨"ï¼Œ"åˆ†éš”
log.dirs=/opt/module/kafka/datas
#topic åœ¨å½“å‰ broker ä¸Šçš„åˆ†åŒºä¸ªæ•°
num.partitions=1
#ç”¨æ¥æ¢å¤å’Œæ¸…ç† data ä¸‹æ•°æ®çš„çº¿ç¨‹æ•°é‡
num.recovery.threads.per.data.dir=1
# æ¯ä¸ª topic åˆ›å»ºæ—¶çš„å‰¯æœ¬æ•°ï¼Œé»˜è®¤æ—¶ 1 ä¸ªå‰¯æœ¬
offsets.topic.replication.factor=1
#segment æ–‡ä»¶ä¿ç•™çš„æœ€é•¿æ—¶é—´ï¼Œè¶…æ—¶å°†è¢«åˆ é™¤
log.retention.hours=168
#æ¯ä¸ª segment æ–‡ä»¶çš„å¤§å°ï¼Œé»˜è®¤æœ€å¤§ 1G
log.segment.bytes=1073741824
# æ£€æŸ¥è¿‡æœŸæ•°æ®çš„æ—¶é—´ï¼Œé»˜è®¤ 5 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æ•°æ®è¿‡æœŸ
log.retention.check.interval.ms=300000
#é…ç½®è¿æ¥ Zookeeper é›†ç¾¤åœ°å€ï¼ˆåœ¨ zk æ ¹ç›®å½•ä¸‹åˆ›å»º/kafkaï¼Œæ–¹ä¾¿ç®¡ç†ï¼‰
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka
```

3ï¼‰åˆ†å‘å®‰è£…åŒ…

```bash
xsync kafka/

scp -r /opt/module/kafka hadoop2:/opt/module/
scp -r /opt/module/kafka hadoop3:/opt/module/
```

4ï¼‰åˆ†åˆ«åœ¨ hadoop103 å’Œ hadoop104 ä¸Šä¿®æ”¹é…ç½®æ–‡ä»¶ `/opt/module/kafka/config/server.properties` ä¸­çš„ `broker.id=1`ã€`broker.id=2`

> æ³¨ï¼šbroker.id ä¸å¾—é‡å¤ï¼Œæ•´ä¸ªé›†ç¾¤ä¸­å”¯ä¸€

```bash
vim kafka/config/server.properties

### ä¿®æ”¹:
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=1

vim kafka/config/server.properties
### ä¿®æ”¹:
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=2

log.dirs=/data/kafka
# or 
log.dirs=/opt/module/kafka/datas

zookeeper.connect=hadoop001:2181,hadoop002:2181,hadoop003:2181/kafka
```

5ï¼‰é…ç½®ç¯å¢ƒå˜é‡

ï¼ˆ1ï¼‰åœ¨ `/etc/profile.d/container_env.sh` æ–‡ä»¶ä¸­å¢åŠ  `kafka` ç¯å¢ƒå˜é‡é…ç½®
```bash
sudo vim /etc/profile.d/container_env.sh

# KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin

scp -r /etc/profile.d/container_env.sh hadoop2:/etc/profile.d/
scp -r /etc/profile.d/container_env.sh hadoop3:/etc/profile.d/
source /etc/profile

### åˆ†å‘ç¯å¢ƒå˜é‡æ–‡ä»¶åˆ°å…¶ä»–èŠ‚ç‚¹ï¼Œå¹¶ source
sudo /home/gardenia/bin/xsync /etc/profile.d/container_env.sh
```

6ï¼‰å¯åŠ¨é›†ç¾¤

ï¼ˆ1ï¼‰å…ˆå¯åŠ¨ Zookeeper é›†ç¾¤ï¼Œç„¶åå¯åŠ¨ Kafka
```bash
zk.sh start
```

ï¼ˆ2ï¼‰ä¾æ¬¡åœ¨ hadoop001ã€hadoop002ã€hadoop003èŠ‚ç‚¹ä¸Šå¯åŠ¨  `Kafka` 
```bash
bin/kafka-server-start.sh -daemon config/server.properties
```

> æ³¨æ„ï¼šé…ç½®æ–‡ä»¶çš„è·¯å¾„è¦èƒ½å¤Ÿåˆ° `server.properties` 
>
> å…³é—­é›†ç¾¤ï¼š`bin/kafka-server-stop.sh` 

#### é›†ç¾¤å¯åœè„šæœ¬

1ï¼‰åœ¨ `/home/gardenia/bin`  ç›®å½•ä¸‹åˆ›å»ºæ–‡ä»¶ `kf.sh` è„šæœ¬æ–‡ä»¶

```bash
#! /bin/bash
case $1 in 
"start"){
	for i in hadoop001 hadoop002 hadoop003
	do
		echo " --------start $i Kafka-------"
		ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"
	done
};;
"stop"){
	for i in hadoop001 hadoop002 hadoop003
	do
		echo " --------stop $i Kafka-------"
		ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh "
	done
};;
esac
```

2ï¼‰æ·»åŠ æ‰§è¡Œæƒé™

```bash
chmod +x kf.sh
```

3ï¼‰é›†ç¾¤å‘½ä»¤

```bash
### å¯åŠ¨é›†ç¾¤
kf.sh start

### åœæ­¢
kf.sh stop
```



## Kafka Commands

![image-20231017105542286](images/image-20231017105542286.png)

### Topic å‘½ä»¤è¡Œæ“ä½œ

```bash
# æŸ¥çœ‹æ“ä½œä¸»é¢˜å‘½ä»¤å‚æ•°
bin/kafka-topics.sh
```

<img src="images/image-20231017105649468.png" alt="image-20231017105649468" style="zoom:80%;" />

```bash
# æŸ¥çœ‹å½“å‰æœåŠ¡å™¨ä¸­çš„æ‰€æœ‰ topic
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list

## åˆ›å»º first topic
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 1 --replication-factor 3 --topic first
é€‰é¡¹è¯´æ˜ï¼š
--topic å®šä¹‰ topic å
--replication-factor å®šä¹‰å‰¯æœ¬æ•°
--partitions å®šä¹‰åˆ†åŒºæ•°

## æŸ¥çœ‹ first ä¸»é¢˜çš„è¯¦æƒ…
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic first

## ä¿®æ”¹åˆ†åŒºæ•°ï¼ˆæ³¨æ„ï¼šåˆ†åŒºæ•°åªèƒ½å¢åŠ ï¼Œä¸èƒ½å‡å°‘ï¼‰
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 3

## åˆ é™¤ topic
bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --delete --topic first
```



### Producer å‘½ä»¤è¡Œæ“ä½œ

```bash
# æŸ¥çœ‹æ“ä½œç”Ÿäº§è€…å‘½ä»¤å‚æ•°
bin/kafka-console-producer.sh
```

![image-20231017110114209](images/image-20231017110114209.png)

```bash
# å‘é€æ¶ˆæ¯
bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first
```



### Consumer å‘½ä»¤è¡Œæ“ä½œ

```bash
# æŸ¥çœ‹æ“ä½œæ¶ˆè´¹è€…å‘½ä»¤å‚æ•°
bin/kafka-console-consumer.sh
```

![image-20231017110217941](images/image-20231017110217941.png)

![image-20231017110321481](images/image-20231017110321481.png)

```bash
## æ¶ˆè´¹ first ä¸»é¢˜ä¸­çš„æ•°æ®
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first

## æŠŠä¸»é¢˜ä¸­æ‰€æœ‰çš„æ•°æ®éƒ½è¯»å–å‡ºæ¥ï¼ˆåŒ…æ‹¬å†å²æ•°æ®ï¼‰
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first
```





## ç”Ÿäº§è€…

### ç”Ÿäº§è€…æ¶ˆæ¯å‘é€æµç¨‹

â€‹	åœ¨æ¶ˆæ¯å‘é€çš„è¿‡ç¨‹ä¸­ï¼Œæ¶‰åŠåˆ°äº†ä¸¤ä¸ªçº¿ç¨‹â€”â€”main çº¿ç¨‹å’Œ Sender çº¿ç¨‹ã€‚åœ¨ main çº¿ç¨‹ä¸­åˆ›å»ºäº†ä¸€ä¸ªåŒç«¯é˜Ÿåˆ— RecordAccumulatorã€‚main çº¿ç¨‹å°†æ¶ˆæ¯å‘é€ç»™ RecordAccumulatorï¼ŒSender çº¿ç¨‹ä¸æ–­ä» RecordAccumulator ä¸­æ‹‰å–æ¶ˆæ¯å‘é€åˆ° Kafka Broker

![image-20231017110829719](images/image-20231017110829719.png)

### ç”Ÿäº§è€…é‡è¦å‚æ•°åˆ—è¡¨

| å‚æ•°åç§°                              | æè¿°                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| bootstrap.servers                     | ç”Ÿ äº§ è€… è¿ æ¥ é›† ç¾¤ æ‰€ éœ€ çš„ broker åœ° å€ æ¸… å• ã€‚ ä¾‹ å¦‚ hadoop102:9092,hadoop103:9092,hadoop104:9092ï¼Œå¯ä»¥è®¾ç½® 1 ä¸ªæˆ–è€…å¤šä¸ªï¼Œä¸­é—´ç”¨é€—å·éš”å¼€ã€‚æ³¨æ„è¿™é‡Œå¹¶ééœ€è¦æ‰€æœ‰çš„ broker åœ°å€ï¼Œå› ä¸ºç”Ÿäº§è€…ä»ç»™å®šçš„ broker é‡ŒæŸ¥æ‰¾åˆ°å…¶ä»– broker ä¿¡æ¯ |
| key.serializer å’Œ value.serializer    | æŒ‡å®šå‘é€æ¶ˆæ¯çš„ key å’Œ value çš„åºåˆ—åŒ–ç±»å‹ã€‚ä¸€å®šè¦å†™å…¨ç±»å     |
| buffer.memory                         | RecordAccumulator ç¼“å†²åŒºæ€»å¤§å°ï¼Œé»˜è®¤ 32m                     |
| batch.size                            | ç¼“å†²åŒºä¸€æ‰¹æ•°æ®æœ€å¤§å€¼ï¼Œé»˜è®¤ 16kã€‚é€‚å½“å¢åŠ è¯¥å€¼ï¼Œå¯ä»¥æé«˜ååé‡ï¼Œä½†æ˜¯å¦‚æœè¯¥å€¼è®¾ç½®å¤ªå¤§ï¼Œä¼šå¯¼è‡´æ•°æ®ä¼ è¾“å»¶è¿Ÿå¢åŠ  |
| linger.ms                             | å¦‚æœæ•°æ®è¿Ÿè¿Ÿæœªè¾¾åˆ° batch.sizeï¼Œsender ç­‰å¾… linger.time ä¹‹åå°±ä¼šå‘é€æ•°æ®ã€‚å•ä½ msï¼Œé»˜è®¤å€¼æ˜¯ 0msï¼Œè¡¨ç¤ºæ²¡æœ‰å»¶è¿Ÿã€‚ç”Ÿäº§ç¯å¢ƒå»ºè®®è¯¥å€¼å¤§å°ä¸º 5-100ms ä¹‹é—´ |
| acks                                  | 0ï¼šç”Ÿäº§è€…å‘é€è¿‡æ¥çš„æ•°æ®ï¼Œä¸éœ€è¦ç­‰æ•°æ®è½ç›˜åº”ç­”ã€‚<br/>1ï¼šç”Ÿäº§è€…å‘é€è¿‡æ¥çš„æ•°æ®ï¼ŒLeader æ”¶åˆ°æ•°æ®ååº”ç­”ã€‚<br/>-1ï¼ˆallï¼‰ï¼šç”Ÿäº§è€…å‘é€è¿‡æ¥çš„æ•°æ®ï¼ŒLeader+ å’Œ isr é˜Ÿåˆ—é‡Œé¢çš„æ‰€æœ‰èŠ‚ç‚¹æ”¶é½æ•°æ®ååº”ç­”ã€‚é»˜è®¤å€¼æ˜¯-1ï¼Œ-1 å’Œ all æ˜¯ç­‰ä»·çš„ |
| max.in.flight.requests.per.connection | å…è®¸æœ€å¤šæ²¡æœ‰è¿”å› ack çš„æ¬¡æ•°ï¼Œé»˜è®¤ä¸º 5ï¼Œå¼€å¯å¹‚ç­‰æ€§è¦ä¿è¯è¯¥å€¼æ˜¯ 1-5 çš„æ•°å­— |
| retries                               | å½“æ¶ˆæ¯å‘é€å‡ºç°é”™è¯¯çš„æ—¶å€™ï¼Œç³»ç»Ÿä¼šé‡å‘æ¶ˆæ¯ã€‚retries è¡¨ç¤ºé‡è¯•æ¬¡æ•°ã€‚é»˜è®¤æ˜¯ int æœ€å¤§å€¼ï¼Œ2147483647ã€‚<br/>å¦‚æœè®¾ç½®äº†é‡è¯•ï¼Œè¿˜æƒ³ä¿è¯æ¶ˆæ¯çš„æœ‰åºæ€§ï¼Œéœ€è¦è®¾ç½®MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1 å¦åˆ™åœ¨é‡è¯•æ­¤å¤±è´¥æ¶ˆæ¯çš„æ—¶å€™ï¼Œå…¶ä»–çš„æ¶ˆæ¯å¯èƒ½å‘é€æˆåŠŸäº† |
| retry.backoff.ms                      | ä¸¤æ¬¡é‡è¯•ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼Œé»˜è®¤æ˜¯ 100ms                         |
| enable.idempotence                    | æ˜¯å¦å¼€å¯å¹‚ç­‰æ€§ï¼Œé»˜è®¤ trueï¼Œå¼€å¯å¹‚ç­‰æ€§                        |
| compression.type                      | ç”Ÿäº§è€…å‘é€çš„æ‰€æœ‰æ•°æ®çš„å‹ç¼©æ–¹å¼ã€‚é»˜è®¤æ˜¯ noneï¼Œä¹Ÿå°±æ˜¯ä¸å‹ç¼©ã€‚<br/>æ”¯æŒå‹ç¼©ç±»å‹ï¼šnoneã€gzipã€snappyã€lz4 å’Œ zstd |



### å¼‚æ­¥å‘é€ API

#### æ™®é€šå¼‚æ­¥å‘é€

> éœ€æ±‚ï¼šåˆ›å»º Kafka ç”Ÿäº§è€…ï¼Œé‡‡ç”¨å¼‚æ­¥çš„æ–¹å¼å‘é€åˆ° Kafka Broker

![image-20231017111532463](images/image-20231017111532463.png)

**Code**

```java
// ä¾èµ–
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.0.0</version>
</dependency>
    
// åˆ›å»ºåŒ…åï¼šcom.atguigu.kafka.producer	
// ä¸å¸¦å›è°ƒå‡½æ•°çš„ API ä»£ç 
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducer {
    public static void main(String[] args) {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,"hadoop002:9092,hadoop003:9092");
        // æŒ‡å®šå¯¹åº”çš„ key å’Œ value çš„åºåˆ—åŒ–ç±»å‹ key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());
        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        // "" hello
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 5; i++) {
            kafkaProducer.send(new ProducerRecord<>("first","gardenia"+i));
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
```

**Test**

```bash
# åœ¨ hadoop102 ä¸Šå¼€å¯ Kafka æ¶ˆè´¹è€…
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first

# åœ¨ IDEA ä¸­æ‰§è¡Œä»£ç ï¼Œè§‚å¯Ÿ hadoop102 æ§åˆ¶å°ä¸­æ˜¯å¦æ¥æ”¶åˆ°æ¶ˆæ¯
```



#### å¸¦å›è°ƒå‡½æ•°çš„å¼‚æ­¥å‘é€

â€‹	å›è°ƒå‡½æ•°ä¼šåœ¨ producer æ”¶åˆ° ack æ—¶è°ƒç”¨ï¼Œä¸ºå¼‚æ­¥è°ƒç”¨ï¼Œè¯¥æ–¹æ³•æœ‰ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯å…ƒæ•°æ®ä¿¡æ¯ï¼ˆRecordMetadataï¼‰å’Œå¼‚å¸¸ä¿¡æ¯ï¼ˆExceptionï¼‰ï¼Œå¦‚æœ Exception ä¸º nullï¼Œè¯´æ˜æ¶ˆæ¯å‘é€æˆåŠŸï¼Œå¦‚æœ Exception ä¸ä¸º nullï¼Œè¯´æ˜æ¶ˆæ¯å‘é€å¤±è´¥

![image-20231017113237132](images/image-20231017113237132.png)

> æ³¨æ„ï¼šæ¶ˆæ¯å‘é€å¤±è´¥ä¼šè‡ªåŠ¨é‡è¯•ï¼Œä¸éœ€è¦åœ¨å›è°ƒå‡½æ•°ä¸­æ‰‹åŠ¨é‡è¯•

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducerCallback {
    public static void main(String[] args) throws InterruptedException {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");
        // æŒ‡å®šå¯¹åº”çš„keyå’Œvalueçš„åºåˆ—åŒ–ç±»å‹ key.serializer
//        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,"org.apache.kafka.common.serialization.StringSerializer");
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        // "" hello
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 500; i++) {
            kafkaProducer.send(new ProducerRecord<>("first", "gardenia" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception == null) {
                        System.out.println("ä¸»é¢˜ï¼š " + metadata.topic() + " åˆ†åŒºï¼š " + metadata.partition());
                    }
                }
            });
            Thread.sleep(2);
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
// Test åŒä¸Š
// åœ¨ IDEA æ§åˆ¶å°è§‚å¯Ÿå›è°ƒä¿¡æ¯
/*
ä¸»é¢˜ï¼šfirst->åˆ†åŒºï¼š0
ä¸»é¢˜ï¼šfirst->åˆ†åŒºï¼š0
ä¸»é¢˜ï¼šfirst->åˆ†åŒºï¼š1
ä¸»é¢˜ï¼šfirst->åˆ†åŒºï¼š1
ä¸»é¢˜ï¼šfirst->åˆ†åŒºï¼š1
*/
```



#### åŒæ­¥å‘é€ API

![image-20231017113510913](images/image-20231017113510913.png)

åªéœ€åœ¨å¼‚æ­¥å‘é€çš„åŸºç¡€ä¸Šï¼Œå†è°ƒç”¨ä¸€ä¸‹ `get()` æ–¹æ³•å³å¯ 

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;
import java.util.concurrent.ExecutionException;

public class CustomProducerSync {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");
        // æŒ‡å®šå¯¹åº”çš„keyå’Œvalueçš„åºåˆ—åŒ–ç±»å‹ key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        // "" hello
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 5; i++) {
            kafkaProducer.send(new ProducerRecord<>("first", "atguigu" + i)).get();
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
// Test åŒä¸Š
```



#### ç”Ÿäº§è€…åˆ†åŒº

ï¼ˆ1ï¼‰ä¾¿äºåˆç†ä½¿ç”¨å­˜å‚¨èµ„æºï¼Œæ¯ä¸ª `Partition` åœ¨ä¸€ä¸ª `Broker` ä¸Šå­˜å‚¨ï¼Œå¯ä»¥æŠŠæµ·é‡çš„æ•°æ®æŒ‰ç…§åˆ†åŒºåˆ‡å‰²æˆä¸€å—ä¸€å—æ•°æ®å­˜å‚¨åœ¨å¤šå°  `Broker` ä¸Šã€‚åˆç†æ§åˆ¶åˆ†åŒºçš„ä»»åŠ¡ï¼Œå¯ä»¥å®ç°è´Ÿè½½å‡è¡¡çš„æ•ˆæœã€‚
ï¼ˆ2ï¼‰æé«˜å¹¶è¡Œåº¦ï¼Œç”Ÿäº§è€…å¯ä»¥ä»¥åˆ†åŒºä¸ºå•ä½å‘é€æ•°æ®ï¼›æ¶ˆè´¹è€…å¯ä»¥ä»¥åˆ†åŒºä¸ºå•ä½è¿›è¡Œæ¶ˆè´¹æ•°æ®ã€‚

<img src="images/image-20231017113720170.png" alt="image-20231017113720170" style="zoom:80%;" />

##### åˆ†åŒºç­–ç•¥

1. é»˜è®¤çš„åˆ†åŒºå™¨  `DefaultPartitioner` 

![image-20231017173714525](images/image-20231017173714525.png)

æ —å­ğŸŒ°
```java
// å°†æ•°æ®å‘å¾€æŒ‡å®š partition çš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚ï¼Œå°†æ‰€æœ‰æ•°æ®å‘å¾€åˆ†åŒº 1 ä¸­
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducerCallbackPartitions {
    public static void main(String[] args) throws InterruptedException {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");

        // æŒ‡å®šå¯¹åº”çš„keyå’Œvalueçš„åºåˆ—åŒ–ç±»å‹ key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        
        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 5; i++) {
            kafkaProducer.send(new ProducerRecord<>("first", 1, "", "hello" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception == null) {
                        System.out.println("ä¸»é¢˜ï¼š " + metadata.topic() + " åˆ†åŒºï¼š " + metadata.partition());
                    }
                }
            });
            Thread.sleep(2);
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
```

åœ¨ hadoop002 ä¸Šå¼€å¯ Kafka æ¶ˆè´¹è€…åï¼Œåœ¨ IDEA ä¸­æ‰§è¡Œä»£ç ï¼Œè§‚å¯Ÿ hadoop002 æ§åˆ¶å°ä¸­æ˜¯å¦æ¥æ”¶åˆ°æ¶ˆæ¯ | åœ¨ IDEA æ§åˆ¶å°è§‚å¯Ÿå›è°ƒä¿¡æ¯

```java
// æ²¡æœ‰æŒ‡æ˜ partition å€¼ä½†æœ‰ key çš„æƒ…å†µä¸‹ï¼Œå°† key çš„ hash å€¼ä¸ topic çš„ partition æ•°è¿›è¡Œå–ä½™å¾—åˆ° partition å€¼
```

2. è‡ªå®šä¹‰åˆ†åŒºå™¨

æ —å­ğŸŒ°
	å®ç°ä¸€ä¸ªåˆ†åŒºå™¨å®ç°ï¼Œå‘é€è¿‡æ¥çš„æ•°æ®ä¸­å¦‚æœåŒ…å« gardeniaï¼Œå°±å‘å¾€ 0 å·åˆ†åŒºï¼Œä¸åŒ…å« gardeniaï¼Œå°±å‘å¾€ 1 å·åˆ†åŒº

```java
// å®šä¹‰ç±»å®ç° Partitioner æ¥å£	é‡å†™ partition() æ–¹æ³•
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import java.util.Map;

public class MyPartitioner implements Partitioner {
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        // è·å–æ•°æ® atguigu  hello
        String msgValues = value.toString();
        int partition;
        if (msgValues.contains("gardenia")) {
            partition = 0;
        } else {
            partition = 1;
        }
        return partition;
    }
}
```

```java
// ä½¿ç”¨åˆ†åŒºå™¨çš„æ–¹æ³•ï¼Œåœ¨ç”Ÿäº§è€…çš„é…ç½®ä¸­æ·»åŠ åˆ†åŒºå™¨å‚æ•°
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducerCallbackPartitions {
    public static void main(String[] args) throws InterruptedException {
        // 0 é…ç½®
        Properties properties = new Properties();

        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");

        // æŒ‡å®šå¯¹åº”çš„keyå’Œvalueçš„åºåˆ—åŒ–ç±»å‹ key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        // å…³è”è‡ªå®šä¹‰åˆ†åŒºå™¨
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, "com.gardenia.kafka.producer.MyPartitioner");

        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 5; i++) {
            kafkaProducer.send(new ProducerRecord<>("first", 1, "", "hello" + i), new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {

                    if (exception == null) {
                        System.out.println("ä¸»é¢˜ï¼š " + metadata.topic() + " åˆ†åŒºï¼š " + metadata.partition());
                    }
                }
            });
            Thread.sleep(2);
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
```



### ç”Ÿäº§è€…	æé«˜ååé‡

<img src="images/image-20231017213139151.png" alt="image-20231017213139151" style="zoom:80%;" />

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducerParameters {
    public static void main(String[] args) {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥kafkaé›†ç¾¤
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");
        // åºåˆ—åŒ–
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        
        // ç¼“å†²åŒºå¤§å°
        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);
        // æ‰¹æ¬¡å¤§å°
        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
        // linger.ms
        properties.put(ProducerConfig.LINGER_MS_CONFIG, 1);
        // å‹ç¼©
        properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
        
        // 1 åˆ›å»ºç”Ÿäº§è€…
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 5; i++) {
            kafkaProducer.send(new ProducerRecord<>("first", "gardenia" + i));
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
```

åœ¨ hadoop002 ä¸Šå¼€å¯ Kafka æ¶ˆè´¹è€…åï¼Œåœ¨ IDEA ä¸­æ‰§è¡Œä»£ç ï¼Œè§‚å¯Ÿ hadoop002 æ§åˆ¶å°ä¸­æ˜¯å¦æ¥æ”¶åˆ°æ¶ˆæ¯



### æ•°æ®å¯é æ€§

#### **ACK åº”ç­”çº§åˆ«**

<img src="images/image-20231017213515239.png" alt="image-20231017213515239" style="zoom:80%;" />

<img src="images/image-20231017213706944.png" alt="image-20231017213706944" style="zoom:80%;" />

<img src="images/image-20231017213728558.png" alt="image-20231017213728558" style="zoom:80%;" />

```java
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducerAcks {
    public static void main(String[] args) {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");
        // æŒ‡å®šå¯¹åº”çš„keyå’Œvalueçš„åºåˆ—åŒ–ç±»å‹ key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // acks
        properties.put(ProducerConfig.ACKS_CONFIG, "1");
        
        // é‡è¯•æ¬¡æ•°
        properties.put(ProducerConfig.RETRIES_CONFIG, 3);
        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

        // 2 å‘é€æ•°æ®
        for (int i = 0; i < 5; i++) {
            kafkaProducer.send(new ProducerRecord<>("first", "gardenia" + i));
        }
        // 3 å…³é—­èµ„æº
        kafkaProducer.close();
    }
}
```



### æ•°æ®å»é‡

#### æ•°æ®ä¼ é€’è¯­ä¹‰

- è‡³å°‘ä¸€æ¬¡ï¼ˆAt Least Onceï¼‰= <span style="color:red">ACKçº§åˆ«è®¾ç½®ä¸º -1 + åˆ†åŒºå‰¯æœ¬å¤§äºç­‰äº 2 + ISR é‡Œåº”ç­”çš„æœ€å°å‰¯æœ¬æ•°é‡å¤§äºç­‰äº 2</span>
- å¤šä¸€æ¬¡ï¼ˆAt Most Onceï¼‰= <span style="color:red">ACKçº§åˆ«è®¾ç½®ä¸º 0</span>
- æ€»ç»“
  - At Least Onceå¯ä»¥ä¿è¯æ•°æ®ä¸ä¸¢å¤±ï¼Œä½†æ˜¯<span style="color:red">ä¸èƒ½ä¿è¯æ•°æ®ä¸é‡å¤</span>
  - At Most Onceå¯ä»¥ä¿è¯æ•°æ®ä¸é‡å¤ï¼Œä½†æ˜¯<span style="color:red">ä¸èƒ½ä¿è¯æ•°æ®ä¸ä¸¢å¤±</span>
- ç²¾ç¡®ä¸€æ¬¡ï¼ˆExactly Onceï¼‰ï¼šå¯¹äºä¸€äº›éå¸¸é‡è¦çš„ä¿¡æ¯ï¼Œæ¯”å¦‚å’Œé’±ç›¸å…³çš„æ•°æ®ï¼Œè¦æ±‚æ•°æ®<span style="color:red">æ—¢ä¸èƒ½é‡å¤ä¹Ÿä¸ä¸¢å¤±</span>

Kafka 0.11 ç‰ˆæœ¬ä»¥åï¼Œå¼•å…¥äº†ä¸€é¡¹é‡å¤§ç‰¹æ€§ï¼š<span style="color:red">å¹‚ç­‰æ€§å’Œäº‹åŠ¡</span>

#### å¹‚ç­‰æ€§åŸç†

<img src="images/image-20231017214504228.png" alt="image-20231017214504228" style="zoom:80%;" />

å¼€å¯å‚æ•° `enable.idempotence`  é»˜è®¤ä¸º trueï¼Œfalse å…³é—­

#### ç”Ÿäº§è€…äº‹åŠ¡

å¼€å¯äº‹åŠ¡ï¼Œå¿…é¡»å¼€å¯å¹‚ç­‰æ€§

<img src="images/image-20231017215107482.png" alt="image-20231017215107482" style="zoom:80%;" />

```java
// Kafka çš„äº‹åŠ¡ä¸€å…±æœ‰å¦‚ä¸‹ 5 ä¸ª API
// 1 åˆå§‹åŒ–äº‹åŠ¡
void initTransactions();

// 2 å¼€å¯äº‹åŠ¡
void beginTransaction() throws ProducerFencedException;

// 3 åœ¨äº‹åŠ¡å†…æäº¤å·²ç»æ¶ˆè´¹çš„åç§»é‡ï¼ˆä¸»è¦ç”¨äºæ¶ˆè´¹è€…ï¼‰
void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, String consumerGroupId) throws ProducerFencedException;

// 4 æäº¤äº‹åŠ¡
void commitTransaction() throws ProducerFencedException;

// 5 æ”¾å¼ƒäº‹åŠ¡ï¼ˆç±»ä¼¼äºå›æ»šäº‹åŠ¡çš„æ“ä½œï¼‰
void abortTransaction() throws ProducerFencedException;
```

```java
// å•ä¸ª Producerï¼Œä½¿ç”¨äº‹åŠ¡ä¿è¯æ¶ˆæ¯çš„ä»…ä¸€æ¬¡å‘é€
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class CustomProducerTranactions {
    public static void main(String[] args) {
        // 0 é…ç½®
        Properties properties = new Properties();
        // è¿æ¥é›†ç¾¤ bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop002:9092,hadoop003:9092");
        // æŒ‡å®šå¯¹åº”çš„keyå’Œvalueçš„åºåˆ—åŒ–ç±»å‹ key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // è®¾ç½®äº‹åŠ¡ idï¼ˆå¿…é¡»ï¼‰ï¼Œäº‹åŠ¡ id ä»»æ„èµ·å
        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "tranactional_id_01");
        // 1 åˆ›å»ºkafkaç”Ÿäº§è€…å¯¹è±¡
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);

        kafkaProducer.initTransactions();
        kafkaProducer.beginTransaction();

        try {
            // 2 å‘é€æ•°æ®
            for (int i = 0; i < 5; i++) {
                kafkaProducer.send(new ProducerRecord<>("first", "gardenia" + i));
            }
            int i = 1 / 0;
            kafkaProducer.commitTransaction();
        } catch (Exception e) {
            kafkaProducer.abortTransaction();
        } finally {
            // 3 å…³é—­èµ„æº
            kafkaProducer.close();
        }
    }
}
```



### æ•°æ®æœ‰åº

<img src="images/image-20231017215713453.png" alt="image-20231017215713453" style="zoom:80%;" />



### æ•°æ®ä¹±åº

1. kafka åœ¨1.x ç‰ˆæœ¬ä¹‹å‰ä¿è¯æ•°æ®å•åˆ†åŒºæœ‰åºï¼Œæ¡ä»¶å¦‚ä¸‹ï¼š

   - `max.in.flight.requests.per.connection=1` ï¼ˆä¸éœ€è¦è€ƒè™‘æ˜¯å¦å¼€å¯å¹‚ç­‰æ€§ï¼‰

2. kafka åœ¨ 1.x åŠä»¥åç‰ˆæœ¬ä¿è¯æ•°æ®å•åˆ†åŒºæœ‰åºï¼Œæ¡ä»¶å¦‚ä¸‹ï¼š

   - æœªå¼€å¯å¹‚ç­‰æ€§	`max.in.flight.requests.per.connection` éœ€è¦è®¾ç½®ä¸º 1

   - å¼€å¯å¹‚ç­‰æ€§	`max.in.flight.requests.per.connection` éœ€è¦è®¾ç½®å°äºç­‰äº 5

     > åœ¨ kafka1.x ä»¥åï¼Œå¯ç”¨å¹‚ç­‰åï¼Œ `kafka` æœåŠ¡ç«¯ä¼šç¼“å­˜ `producer` å‘æ¥çš„æœ€è¿‘ 5 ä¸ª `request` çš„å…ƒæ•°æ®ï¼Œ
     > æ•…æ— è®ºå¦‚ä½•ï¼Œéƒ½å¯ä»¥ä¿è¯æœ€è¿‘ 5 ä¸ª `request` çš„æ•°æ®éƒ½æ˜¯æœ‰åºçš„

![image-20231017220112993](images/image-20231017220112993.png)



## Kafka Broker

### Broker å·¥ä½œæµç¨‹

#### Zookeeper å­˜å‚¨çš„ Kafka ä¿¡æ¯

```bash
# å¯åŠ¨ Zookeeper å®¢æˆ·ç«¯
[@hadoop002 zookeeper]$ bin/zkCli.sh

# é€šè¿‡ ls å‘½ä»¤å¯ä»¥æŸ¥çœ‹ kafka ç›¸å…³ä¿¡æ¯
ls /kafka
```

<img src="images/image-20231017223925733.png" alt="image-20231017223925733" style="zoom:80%;" />

#### Broker æ€»ä½“å·¥ä½œæµç¨‹

![image-20231017224058555](images/image-20231017224058555.png)

```bash
### Kafka ä¸Šä¸‹çº¿ï¼ŒZookeeper ä¸­æ•°æ®å˜åŒ–
# æŸ¥çœ‹ /kafka/brokers/ids è·¯å¾„ä¸Šçš„èŠ‚ç‚¹
ls /kafka/brokers/ids

# æŸ¥çœ‹ /kafka/controller è·¯å¾„ä¸Šçš„æ•°æ®
get /kafka/controller

# æŸ¥çœ‹ /kafka/brokers/topics/first/partitions/0/state è·¯å¾„ä¸Šçš„æ•°æ®
get /kafka/brokers/topics/first/partitions/0/state

# åœæ­¢ hadoop003 ä¸Šçš„ kafka
bin/kafka-server-stop.sh

# é‡å¤ æŸ¥çœ‹ Zookeeper é‡Œçš„å†…å®¹
```

#### Broker é‡è¦å‚æ•°

| å‚æ•°åç§°                                | æè¿°                                                         |
| --------------------------------------- | ------------------------------------------------------------ |
| replica.lag.time.max.ms                 | ISR ä¸­ï¼Œå¦‚æœ Follower é•¿æ—¶é—´æœªå‘ Leader å‘é€é€šä¿¡è¯·æ±‚æˆ–åŒæ­¥æ•°æ®ï¼Œåˆ™è¯¥ Follower å°†è¢«è¸¢å‡º ISRã€‚<br/>è¯¥æ—¶é—´é˜ˆå€¼ï¼Œé»˜è®¤ 30s |
| auto.leader.rebalance.enable            | é»˜è®¤æ˜¯ trueã€‚ è‡ªåŠ¨ Leader Partition å¹³è¡¡                     |
| leader.imbalance.per.broker.percentage  | é»˜è®¤æ˜¯ 10%ã€‚æ¯ä¸ª broker å…è®¸çš„ä¸å¹³è¡¡çš„ leader çš„æ¯”ç‡ã€‚å¦‚æœæ¯ä¸ª broker è¶…è¿‡äº†è¿™ä¸ªå€¼ï¼Œæ§åˆ¶å™¨ä¼šè§¦å‘ leader çš„å¹³è¡¡ |
| leader.imbalance.check.interval.seconds | é»˜è®¤å€¼ 300 ç§’ã€‚æ£€æŸ¥ leader è´Ÿè½½æ˜¯å¦å¹³è¡¡çš„é—´éš”æ—¶é—´            |
| log.segment.bytes                       | Kafka ä¸­ log æ—¥å¿—æ˜¯åˆ†æˆä¸€å—å—å­˜å‚¨çš„ï¼Œæ­¤é…ç½®æ˜¯æŒ‡ log æ—¥å¿—åˆ’åˆ† æˆå—çš„å¤§å°ï¼Œé»˜è®¤å€¼ 1G |
| log.index.interval.bytes                | é»˜è®¤ 4kbï¼Œkafka é‡Œé¢æ¯å½“å†™å…¥äº† 4kb å¤§å°çš„æ—¥å¿—ï¼ˆ.logï¼‰ï¼Œç„¶åå°±å¾€ index æ–‡ä»¶é‡Œé¢è®°å½•ä¸€ä¸ªç´¢å¼• |
| log.retention.hours                     | Kafka ä¸­æ•°æ®ä¿å­˜çš„æ—¶é—´ï¼Œé»˜è®¤ 7 å¤©                            |
| log.retention.minutes                   | Kafka ä¸­æ•°æ®ä¿å­˜çš„æ—¶é—´ï¼Œåˆ†é’Ÿçº§åˆ«ï¼Œé»˜è®¤å…³é—­                   |
| log.retention.ms                        | Kafka ä¸­æ•°æ®ä¿å­˜çš„æ—¶é—´ï¼Œæ¯«ç§’çº§åˆ«ï¼Œé»˜è®¤å…³é—­                   |
| log.retention.check.interval.ms         | æ£€æŸ¥æ•°æ®æ˜¯å¦ä¿å­˜è¶…æ—¶çš„é—´éš”ï¼Œé»˜è®¤æ˜¯ 5 åˆ†é’Ÿ                    |
| log.retention.bytes                     | é»˜è®¤ç­‰äº-1ï¼Œè¡¨ç¤ºæ— ç©·å¤§ã€‚è¶…è¿‡è®¾ç½®çš„æ‰€æœ‰æ—¥å¿—æ€»å¤§å°ï¼Œåˆ é™¤æœ€æ—©çš„ segment |
| log.cleanup.policy                      | é»˜è®¤æ˜¯ deleteï¼Œè¡¨ç¤ºæ‰€æœ‰æ•°æ®å¯ç”¨åˆ é™¤ç­–ç•¥ï¼›<br/>å¦‚æœè®¾ç½®å€¼ä¸º compactï¼Œè¡¨ç¤ºæ‰€æœ‰æ•°æ®å¯ç”¨å‹ç¼©ç­–ç•¥ |
| num.io.threads                          | é»˜è®¤æ˜¯ 8ã€‚è´Ÿè´£å†™ç£ç›˜çš„çº¿ç¨‹æ•°ã€‚æ•´ä¸ªå‚æ•°å€¼è¦å æ€»æ ¸æ•°çš„ 50%     |
| num.replica.fetchers                    | å‰¯æœ¬æ‹‰å–çº¿ç¨‹æ•°ï¼Œè¿™ä¸ªå‚æ•°å æ€»æ ¸æ•°çš„ 50% çš„ 1/3                |
| num.network.threads                     | é»˜è®¤æ˜¯ 3ã€‚æ•°æ®ä¼ è¾“çº¿ç¨‹æ•°ï¼Œè¿™ä¸ªå‚æ•°å æ€»æ ¸æ•°çš„50%çš„ 2/3        |
| log.flush.interval.messages             | å¼ºåˆ¶é¡µç¼“å­˜åˆ·å†™åˆ°ç£ç›˜çš„æ¡æ•°ï¼Œé»˜è®¤æ˜¯ long çš„æœ€å¤§å€¼ï¼Œ9223372036854775807ã€‚ä¸€èˆ¬ä¸å»ºè®®ä¿®æ”¹ï¼Œäº¤ç»™ç³»ç»Ÿè‡ªå·±ç®¡ç† |
| log.flush.interval.ms                   | æ¯éš”å¤šä¹…ï¼Œåˆ·æ•°æ®åˆ°ç£ç›˜ï¼Œé»˜è®¤æ˜¯ nullã€‚ä¸€èˆ¬ä¸å»ºè®®ä¿®æ”¹ï¼Œäº¤ç»™ç³»ç»Ÿè‡ªå·±ç®¡ç† |



### èŠ‚ç‚¹æœå½¹å’Œé€€å½¹

#### æœå½¹æ–°èŠ‚ç‚¹

```bash
### æ–°èŠ‚ç‚¹å‡†å¤‡
# å…³é—­ hadoop004ï¼Œå¹¶å³é”®æ‰§è¡Œå…‹éš†æ“ä½œ & å¼€å¯ä¸€ä¸ªæ–°çš„å®¹å™¨
# å¼€å¯ hadoop005ï¼Œå¹¶ä¿®æ”¹ IP åœ°å€
vim /etc/sysconfig/network-scripts/ifcfg-ens160

DEVICE=ens160
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
IPADDR=192.168.9.5
PREFIX=24
GATEWAY=192.168.9.1
DNS1=8.8.8.8

# åœ¨ hadoop005 ä¸Šï¼Œä¿®æ”¹ä¸»æœºåç§°ä¸º hadoop005
vim /etc/hostname hadoop005

# é‡æ–°å¯åŠ¨ hadoop004ã€hadoop005
# ä¿®æ”¹ haodoop005 ä¸­ kafka çš„ broker.id ä¸º 3
# åˆ é™¤ hadoop005 ä¸­ kafka ä¸‹çš„ datas å’Œ logs
rm -rf datas/* logs/*

# å¯åŠ¨ hadoop002ã€hadoop003ã€hadoop004 ä¸Šçš„ kafka é›†ç¾¤
zk.sh start
kf.sh start

# å•ç‹¬å¯åŠ¨ hadoop005 ä¸­çš„ kafka
bin/kafka-server-start.sh -daemon ./config/server.properties
```

```BASH
### è´Ÿè½½å‡è¡¡
# åˆ›å»ºä¸€ä¸ªè¦å‡è¡¡çš„ä¸»é¢˜
vim topics-to-move.json
{
	"topics": [
		{"topic": "first"}
	],
	"version": 1
}

# ç”Ÿæˆä¸€ä¸ªè´Ÿè½½å‡è¡¡çš„è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --topics-to-move-json-file topics-to-move.json --broker-list "0,1,2,3" --generate

# åˆ›å»ºå‰¯æœ¬å­˜å‚¨è®¡åˆ’ï¼ˆæ‰€æœ‰å‰¯æœ¬å­˜å‚¨åœ¨ broker0ã€broker1ã€broker2ã€broker3 ä¸­ï¼‰
vim increase-replication-factor.json
{"version":1,"partitions":[{"topic":"first","partition":0,"replicas":[2,3,0],"log_dirs":["any","any","any"]},{"topic":"first","partition":1,"replicas":[3,0,1],"log_dirs":["any","any","any"]},{"topic":"first","partition":2,"replicas":[0,1,2],"log_dirs":["any","any","any"]}]}

# æ‰§è¡Œå‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --execute

# éªŒè¯å‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --verify
```



### é€€å½¹æ—§èŠ‚ç‚¹

å…ˆæŒ‰ç…§é€€å½¹ä¸€å°èŠ‚ç‚¹ï¼Œç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œç„¶åæŒ‰ç…§æœå½¹æ—¶æ“ä½œæµç¨‹æ‰§è¡Œè´Ÿè½½å‡è¡¡

```bash
### è´Ÿè½½å‡è¡¡
# åˆ›å»ºä¸€ä¸ªè¦å‡è¡¡çš„ä¸»é¢˜
vim topics-to-move.json
{
	"topics": [
		{"topic": "first"}
	],
	"version": 1
}

# åˆ›å»ºæ‰§è¡Œè®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --topics-to-move-json-file topics-to-move.json --broker-list "0,1,2" --generate

# åˆ›å»ºå‰¯æœ¬å­˜å‚¨è®¡åˆ’ï¼ˆæ‰€æœ‰å‰¯æœ¬å­˜å‚¨åœ¨ broker0ã€broker1ã€broker2 ä¸­ï¼‰
vim increase-replication-factor.json
{"version":1,"partitions":[{"topic":"first","partition":0,"replicas":[2,0,1],"log_dirs":["any","any","any"]},{"topic":"first","partition":1,"replicas":[0,1,2],"log_dirs":["any","any","any"]},{"topic":"first","partition":2,"replicas":[1,2,0],"log_dirs":["any","any","any"]}]}

# æ‰§è¡Œå‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --execute

# éªŒè¯å‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --verify
```

```bash
# æ‰§è¡Œåœæ­¢å‘½ä»¤	åœ¨ hadoop005 ä¸Šæ‰§è¡Œåœæ­¢å‘½ä»¤å³å¯
bin/kafka-server-stop.sh
```



### Kafka å‰¯æœ¬

#### å‰¯æœ¬åŸºæœ¬ä¿¡æ¯

1. Kafka å‰¯æœ¬ä½œç”¨ï¼šæé«˜æ•°æ®å¯é æ€§
2. Kafka é»˜è®¤å‰¯æœ¬ 1 ä¸ªï¼Œç”Ÿäº§ç¯å¢ƒä¸€èˆ¬é…ç½®ä¸º 2 ä¸ªï¼Œä¿è¯æ•°æ®å¯é æ€§ï¼›å¤ªå¤šå‰¯æœ¬ä¼šå¢åŠ ç£ç›˜å­˜å‚¨ç©ºé—´ï¼Œå¢åŠ ç½‘ç»œä¸Šæ•°æ®ä¼ è¾“ï¼Œé™ä½æ•ˆç‡
3. Kafka ä¸­å‰¯æœ¬åˆ†ä¸ºï¼šLeader å’Œ Followerã€‚Kafka ç”Ÿäº§è€…åªä¼šæŠŠæ•°æ®å‘å¾€ Leaderï¼Œç„¶å Follower æ‰¾ Leader è¿›è¡ŒåŒæ­¥æ•°æ®
4. Kafka åˆ†åŒºä¸­çš„æ‰€æœ‰å‰¯æœ¬ç»Ÿç§°ä¸º ARï¼ˆAssigned Repllicasï¼‰
   - AR = ISR + OSR
   - ISRï¼Œè¡¨ç¤ºå’Œ Leader ä¿æŒåŒæ­¥çš„ Follower é›†åˆã€‚å¦‚æœ Follower é•¿æ—¶é—´æœªå‘ Leader å‘é€é€šä¿¡è¯·æ±‚æˆ–åŒæ­¥æ•°æ®ï¼Œåˆ™è¯¥ Follower å°†è¢«è¸¢å‡º ISRã€‚è¯¥æ—¶é—´é˜ˆå€¼ç”± `replica.lag.time.max.ms` å‚æ•°è®¾å®šï¼Œé»˜è®¤ 30sã€‚Leader å‘ç”Ÿæ•…éšœä¹‹åï¼Œå°±ä¼šä» ISR ä¸­é€‰ä¸¾æ–°çš„ Leader
   - OSRï¼Œè¡¨ç¤º Follower ä¸ Leader å‰¯æœ¬åŒæ­¥æ—¶ï¼Œå»¶è¿Ÿè¿‡å¤šçš„å‰¯æœ¬

#### Leader é€‰ä¸¾æµç¨‹

â€‹	Kafka é›†ç¾¤ä¸­æœ‰ä¸€ä¸ª broker çš„ Controller ä¼šè¢«é€‰ä¸¾ä¸º Controller Leaderï¼Œè´Ÿè´£ç®¡ç†é›†ç¾¤ broker çš„ä¸Šä¸‹çº¿ï¼Œæ‰€æœ‰ topic çš„åˆ†åŒºå‰¯æœ¬åˆ†é…å’Œ Leader é€‰ä¸¾ç­‰å·¥ä½œã€‚
â€‹	Controller çš„ä¿¡æ¯åŒæ­¥å·¥ä½œæ˜¯ä¾èµ–äº Zookeeper 

<img src="images/image-20231017231630428.png" alt="image-20231017231630428" style="zoom:80%;" />

```bash
# åˆ›å»ºä¸€ä¸ªæ–°çš„ topicï¼Œ4 ä¸ªåˆ†åŒºï¼Œ4 ä¸ªå‰¯æœ¬
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --create --topic gardenia01 --partitions 4 --replication-factor 4

# æŸ¥çœ‹ Leader åˆ†å¸ƒæƒ…å†µ
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic gardenia01

# åœæ­¢æ‰ hadoop005 çš„ kafka è¿›ç¨‹ï¼Œå¹¶æŸ¥çœ‹ Leader åˆ†åŒºæƒ…å†µ
bin/kafka-server-stop.sh
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic gardenia01

# åœæ­¢æ‰ hadoop004 çš„ kafka è¿›ç¨‹ï¼Œå¹¶æŸ¥çœ‹ Leader åˆ†åŒºæƒ…å†µ
bin/kafka-server-stop.sh
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic gardenia01

# å¯åŠ¨ hadoop005 çš„ kafka è¿›ç¨‹ï¼Œå¹¶æŸ¥çœ‹ Leader åˆ†åŒºæƒ…å†µ
bin/kafka-server-start.sh -daemon config/server.properties
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic gardenia01

# å¯åŠ¨ hadoop004 çš„ kafka è¿›ç¨‹ï¼Œå¹¶æŸ¥çœ‹ Leader åˆ†åŒºæƒ…å†µ
bin/kafka-server-start.sh -daemon config/server.properties
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic gardenia01

# åœæ­¢æ‰ hadoop003 çš„ kafka è¿›ç¨‹ï¼Œå¹¶æŸ¥çœ‹ Leader åˆ†åŒºæƒ…å†µ
bin/kafka-server-stop.sh
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic gardenia01
```



#### Leader å’Œ Follower æ•…éšœå¤„ç†ç»†èŠ‚

â€‹	<span style="color:red">LEOï¼ˆLog End Offsetï¼‰</span>ï¼šæ¯ä¸ªå‰¯æœ¬çš„æœ€åä¸€ä¸ª `offset` ï¼ŒLEOå…¶å®å°±æ˜¯æœ€æ–°çš„ `offset + 1` 

â€‹	<span style="color:red">HWï¼ˆHigh Watermarkï¼‰</span>ï¼šæ‰€æœ‰å‰¯æœ¬ä¸­æœ€å°çš„ LEO

<img src="images/image-20231017232354915.png" alt="image-20231017232354915" style="zoom:80%;" />

<img src="images/image-20231017232422949.png" alt="image-20231017232422949" style="zoom:80%;" />

#### åˆ†åŒºå‰¯æœ¬åˆ†é…

â€‹	å¦‚æœ kafka æœåŠ¡å™¨åªæœ‰ 4 ä¸ªèŠ‚ç‚¹ï¼Œé‚£ä¹ˆè®¾ç½® kafka çš„åˆ†åŒºæ•°å¤§äºæœåŠ¡å™¨å°æ•°ï¼Œåœ¨ kafka åº•å±‚å¦‚ä½•åˆ†é…å­˜å‚¨å‰¯æœ¬å‘¢ï¼Ÿ

```bash
### åˆ›å»º 16 åˆ†åŒºï¼Œ3 ä¸ªå‰¯æœ¬
# åˆ›å»ºä¸€ä¸ªæ–°çš„ topicï¼Œåç§°ä¸º second
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --create --partitions 16 --replication-factor 3 --topic second

# æŸ¥çœ‹åˆ†åŒºå’Œå‰¯æœ¬æƒ…å†µ
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic second
```

<img src="images/image-20231017232636362.png" alt="image-20231017232636362" style="zoom: 50%;" />

### æ‰‹åŠ¨è°ƒæ•´åˆ†åŒºå‰¯æœ¬å­˜å‚¨

â€‹	åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¯å°æœåŠ¡å™¨çš„é…ç½®å’Œæ€§èƒ½ä¸ä¸€è‡´ï¼Œä½†æ˜¯ `Kafka` åªä¼šæ ¹æ®è‡ªå·±çš„ä»£ç è§„åˆ™åˆ›å»ºå¯¹åº”çš„åˆ†åŒºå‰¯æœ¬ï¼Œå°±ä¼šå¯¼è‡´ä¸ªåˆ«æœåŠ¡å™¨å­˜å‚¨å‹åŠ›è¾ƒå¤§ã€‚æ‰€æœ‰éœ€è¦æ‰‹åŠ¨è°ƒæ•´åˆ†åŒºå‰¯æœ¬çš„å­˜å‚¨ã€‚

â€‹	éœ€æ±‚ï¼š<span style="color:red">åˆ›å»ºä¸€ä¸ªæ–°çš„ `topic` ï¼Œ4ä¸ªåˆ†åŒºï¼Œä¸¤ä¸ªå‰¯æœ¬ï¼Œåç§°ä¸º threeã€‚å°†è¯¥ `topic` çš„æ‰€æœ‰å‰¯æœ¬éƒ½å­˜å‚¨åˆ° `broker0` å’Œ `broker1` ä¸¤å°æœåŠ¡å™¨ä¸Šã€‚</span>

<img src="images/image-20231017232924243.png" alt="image-20231017232924243" style="zoom:67%;" />

æ‰‹åŠ¨è°ƒæ•´åˆ†åŒºå‰¯æœ¬å­˜å‚¨çš„æ­¥éª¤å¦‚ä¸‹ï¼š

```bash
# åˆ›å»ºä¸€ä¸ªæ–°çš„ topicï¼Œåç§°ä¸º three
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --create --partitions 4 --replication-factor 2 --topic three

# æŸ¥çœ‹åˆ†åŒºå‰¯æœ¬å­˜å‚¨æƒ…å†µ
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic three

# åˆ›å»ºå‰¯æœ¬å­˜å‚¨è®¡åˆ’ï¼ˆæ‰€æœ‰å‰¯æœ¬éƒ½æŒ‡å®šå­˜å‚¨åœ¨ broker0ã€broker1 ä¸­ï¼‰
vim increase-replication-factor.json
{
	"version":1,
	"partitions":[{"topic":"three","partition":0,"replicas":[0,1]},
		{"topic":"three","partition":1,"replicas":[0,1]},
		{"topic":"three","partition":2,"replicas":[1,0]},
		{"topic":"three","partition":3,"replicas":[1,0]}]
}

# æ‰§è¡Œå‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --execute

# éªŒè¯å‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --verify

 # æŸ¥çœ‹åˆ†åŒºå‰¯æœ¬å­˜å‚¨æƒ…å†µ
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --describe --topic three
```



### Leader Partition è´Ÿè½½å¹³è¡¡

â€‹	æ­£å¸¸æƒ…å†µä¸‹ï¼ŒKafka æœ¬èº«ä¼šè‡ªåŠ¨æŠŠ `Leader Partition` å‡åŒ€åˆ†æ•£åœ¨å„ä¸ªæœºå™¨ä¸Šï¼Œæ¥ä¿è¯æ¯å°æœºå™¨çš„è¯»å†™ååé‡éƒ½æ˜¯å‡åŒ€çš„ã€‚ä½†æ˜¯å¦‚æœæŸäº› `broker` å®•æœºï¼Œä¼šå¯¼è‡´ `Leader Partition` è¿‡äºé›†ä¸­åœ¨å…¶ä»–å°‘éƒ¨åˆ†å‡ å° `broker` ä¸Šï¼Œè¿™ä¼šå¯¼è‡´å°‘æ•°å‡ å° `broker` çš„è¯»å†™è¯·æ±‚å‹åŠ›è¿‡é«˜ï¼Œå…¶ä»–å®•æœºçš„ `broker` é‡å¯ä¹‹åéƒ½æ˜¯ `follower partition` ï¼Œè¯»å†™è¯·æ±‚å¾ˆä½ï¼Œé€ æˆé›†ç¾¤è´Ÿè½½ä¸å‡è¡¡ã€‚

![image-20231017233304604](images/image-20231017233304604.png)

<img src="images/image-20231017233316998.png" alt="image-20231017233316998" style="zoom:67%;" />

### å¢åŠ å‰¯æœ¬å› å­

â€‹	åœ¨ç”Ÿäº§ç¯å¢ƒå½“ä¸­ï¼Œç”±äºæŸä¸ªä¸»é¢˜çš„é‡è¦ç­‰çº§éœ€è¦æå‡ï¼Œæˆ‘ä»¬è€ƒè™‘å¢åŠ å‰¯æœ¬ã€‚å‰¯æœ¬æ•°çš„å¢åŠ éœ€è¦å…ˆåˆ¶å®šè®¡åˆ’ï¼Œç„¶åæ ¹æ®è®¡åˆ’æ‰§è¡Œã€‚

```bash
# åˆ›å»º topic
bin/kafka-topics.sh --bootstrap-server hadoop002:9092 --create --partitions 3 --replication-factor 1 --topic four

### æ‰‹åŠ¨å¢åŠ å‰¯æœ¬å­˜å‚¨
# åˆ›å»ºå‰¯æœ¬å­˜å‚¨è®¡åˆ’ï¼ˆæ‰€æœ‰å‰¯æœ¬éƒ½æŒ‡å®šå­˜å‚¨åœ¨ broker0ã€broker1ã€broker2 ä¸­ï¼‰
vim increase-replication-factor.json
{"version":1,"partitions":[{"topic":"four","partition":0,"replicas":[0,1,2]},{"topic":"four","partition":1,"replicas":[0,1,2]},{"topic":"four","partition":2,"replicas":[0,1,2]}]}

# æ‰§è¡Œå‰¯æœ¬å­˜å‚¨è®¡åˆ’
bin/kafka-reassign-partitions.sh --bootstrap-server hadoop002:9092 --reassignment-json-file increase-replication-factor.json --execute
```



## æ–‡ä»¶å­˜å‚¨æœºåˆ¶

### Topic æ•°æ®çš„å­˜å‚¨æœºåˆ¶

![image-20231017233840773](images/image-20231017233840773.png)

```bash
# æŸ¥çœ‹ hadoop102ï¼ˆæˆ–è€… hadoop103ã€hadoop104ï¼‰çš„/opt/module/kafka/datas/first-1ï¼ˆfirst-0ã€first-2ï¼‰è·¯å¾„ä¸Šçš„æ–‡ä»¶
ls kafka/datas/first-1

# é€šè¿‡å·¥å…·æŸ¥çœ‹ index å’Œ log ä¿¡æ¯
kafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.index
kafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.log
```

### index æ–‡ä»¶å’Œ log æ–‡ä»¶

<img src="images/image-20231017234126456.png" alt="image-20231017234126456" style="zoom:80%;" />

<img src="images/image-20231017234140034.png" alt="image-20231017234140034" style="zoom:67%;" />

### æ–‡ä»¶æ¸…ç†ç­–ç•¥

Kafka ä¸­é»˜è®¤çš„<span style="color:red">æ—¥å¿—ä¿å­˜æ—¶é—´ä¸º 7 å¤©</span>ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´å¦‚ä¸‹å‚æ•°ä¿®æ”¹ä¿å­˜æ—¶é—´

- `log.retention.hours`	æœ€ä½ä¼˜å…ˆçº§å°æ—¶ï¼Œé»˜è®¤ 7 å¤©
- `log.retention.minutes`	åˆ†é’Ÿ
- `log.retention.ms`	æœ€é«˜ä¼˜å…ˆçº§æ¯«ç§’
- `log.retention.check.interval.ms`	è´Ÿè´£è®¾ç½®æ£€æŸ¥å‘¨æœŸï¼Œé»˜è®¤ 5 åˆ†é’Ÿ

Kafka ä¸­æä¾›çš„æ—¥å¿—æ¸…ç†ç­–ç•¥æœ‰ <span style="color:red">delete</span> å’Œ <span style="color:red">compact</span> ä¸¤ç§

1. `delete` æ—¥å¿—åˆ é™¤ï¼šå°†è¿‡æœŸæ•°æ®åˆ é™¤

   - `log.cleanup.policy = delete`  æ‰€æœ‰æ•°æ®å¯ç”¨åˆ é™¤ç­–ç•¥

     ï¼ˆ1ï¼‰åŸºäºæ—¶é—´ï¼šé»˜è®¤æ‰“å¼€ã€‚ä»¥ segment ä¸­æ‰€æœ‰è®°å½•ä¸­çš„æœ€å¤§æ—¶é—´æˆ³ä½œä¸ºè¯¥æ–‡ä»¶æ—¶é—´æˆ³
     ï¼ˆ2ï¼‰åŸºäºå¤§å°ï¼šé»˜è®¤å…³é—­ã€‚è¶…è¿‡è®¾ç½®çš„æ‰€æœ‰æ—¥å¿—æ€»å¤§å°ï¼Œåˆ é™¤æœ€æ—©çš„ segment
     	`log.retention.bytes` ï¼Œé»˜è®¤ç­‰äº-1ï¼Œè¡¨ç¤ºæ— ç©·å¤§ã€‚

2. compact æ—¥å¿—å‹ç¼©

   - å¯¹äºç›¸åŒ key çš„ä¸åŒ value å€¼ï¼Œåªä¿ç•™æœ€åä¸€ä¸ªç‰ˆæœ¬

   - `log.cleanup.policy = compact`  æ‰€æœ‰æ•°æ®å¯ç”¨å‹ç¼©ç­–ç•¥

     <img src="images/image-20231017234645421.png" alt="image-20231017234645421" style="zoom:67%;" />

â€‹	å‹ç¼©åçš„ offset å¯èƒ½æ˜¯ä¸è¿ç»­çš„ï¼Œæ¯”å¦‚ä¸Šå›¾ä¸­æ²¡æœ‰ 6ï¼Œå½“ä»è¿™äº› `offset` æ¶ˆè´¹æ¶ˆæ¯æ—¶ï¼Œå°†ä¼šæ‹¿åˆ°æ¯”è¿™ä¸ª `offset `å¤§çš„ `offset` å¯¹åº”çš„æ¶ˆæ¯ï¼Œå®é™…ä¸Šä¼šæ‹¿åˆ° `offse` tä¸º 7 çš„æ¶ˆæ¯ï¼Œå¹¶ä»è¿™ä¸ªä½ç½®å¼€å§‹æ¶ˆè´¹ã€‚
â€‹	è¿™ç§ç­–ç•¥åªé€‚åˆç‰¹æ®Šåœºæ™¯ï¼Œæ¯”å¦‚æ¶ˆæ¯çš„ `key `æ˜¯ç”¨æˆ·IDï¼Œvalue æ˜¯ç”¨æˆ·çš„èµ„æ–™ï¼Œé€šè¿‡è¿™ç§å‹ç¼©ç­–ç•¥ï¼Œæ•´ä¸ªæ¶ˆæ¯é›†é‡Œå°±ä¿å­˜äº†æ‰€æœ‰ç”¨æˆ·æœ€æ–°çš„èµ„æ–™ã€‚

### é«˜æ•ˆè¯»å†™æ•°æ®

1ï¼‰Kafka æœ¬èº«æ˜¯åˆ†å¸ƒå¼é›†ç¾¤ï¼Œå¯ä»¥é‡‡ç”¨åˆ†åŒºæŠ€æœ¯ï¼Œå¹¶è¡Œåº¦é«˜

2ï¼‰è¯»æ•°æ®é‡‡ç”¨ç¨€ç–ç´¢å¼•ï¼Œå¯ä»¥å¿«é€Ÿå®šä½è¦æ¶ˆè´¹çš„æ•°æ®

3ï¼‰é¡ºåºå†™ç£ç›˜
	Kafka çš„ producer ç”Ÿäº§æ•°æ®ï¼Œè¦å†™å…¥åˆ° log æ–‡ä»¶ä¸­ï¼Œå†™çš„è¿‡ç¨‹æ˜¯ä¸€ç›´è¿½åŠ åˆ°æ–‡ä»¶æœ«ç«¯ï¼Œä¸ºé¡ºåºå†™ã€‚å®˜ç½‘æœ‰æ•°æ®è¡¨æ˜ï¼ŒåŒæ ·çš„ç£ç›˜ï¼Œé¡ºåºå†™èƒ½åˆ° 600M/sï¼Œè€Œéšæœºå†™åªæœ‰ 100K/sã€‚è¿™ä¸ç£ç›˜çš„æœºæ¢°æœºæ„æœ‰å…³ï¼Œé¡ºåºå†™ä¹‹æ‰€ä»¥å¿«ï¼Œæ˜¯å› ä¸ºå…¶çœå»äº†å¤§é‡ç£å¤´å¯»å€çš„æ—¶é—´ã€‚

<img src="images/image-20231017234923349.png" alt="image-20231017234923349" style="zoom: 67%;" />

4ï¼‰é¡µç¼“å­˜ + é›¶æ‹·è´æŠ€æœ¯

â€‹	é›¶æ‹·è´ï¼šKafka çš„æ•°æ®åŠ å·¥å¤„ç†æ“ä½œäº¤ç”± Kafka ç”Ÿäº§è€…å’Œ Kafka æ¶ˆè´¹è€…å¤„ç†ã€‚Kafka Broker åº”ç”¨å±‚ä¸å…³å¿ƒå­˜å‚¨çš„æ•°æ®ï¼Œæ‰€ä»¥å°±ä¸ç”¨
èµ°åº”ç”¨å±‚ï¼Œä¼ è¾“æ•ˆç‡é«˜ã€‚
â€‹	`PageCache` é¡µ ç¼“ å­˜ ï¼š Kafka é‡åº¦ä¾èµ–åº•å±‚æ“ä½œç³»ç»Ÿæä¾›çš„ `PageCache` åŠŸ èƒ½ã€‚å½“ä¸Šå±‚æœ‰å†™æ“ä½œæ—¶ï¼Œæ“ä½œç³»ç»Ÿåªæ˜¯å°†æ•°æ®å†™å…¥
`PageCache` ã€‚å½“è¯»æ“ä½œå‘ç”Ÿæ—¶ï¼Œå…ˆä» `PageCache` ä¸­æŸ¥æ‰¾ï¼Œå¦‚æœæ‰¾ä¸åˆ°ï¼Œå†å»ç£ç›˜ä¸­è¯»å–ã€‚å®é™…ä¸Š `PageCache` æ˜¯æŠŠå°½å¯èƒ½å¤šçš„ç©ºé—²å†…å­˜
éƒ½å½“åšäº†ç£ç›˜ç¼“å­˜æ¥ä½¿ç”¨ã€‚

![image-20231017235159656](images/image-20231017235159656.png)

![image-20231017235206756](images/image-20231017235206756.png)

<hr>

## æ¶ˆè´¹è€…













