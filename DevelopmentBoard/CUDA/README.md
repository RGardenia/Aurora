# CUDA

## ç®€ä»‹

> â€‹		CUDA æ˜¯ NVIDIA æ¨å‡ºçš„ç”¨äºå…¶å‘å¸ƒçš„ GPU çš„å¹¶è¡Œè®¡ç®—æ¶æ„ï¼Œä½¿ç”¨ CUDA å¯ä»¥åˆ©ç”¨ GPU çš„å¹¶è¡Œè®¡ç®—å¼•æ“æ›´åŠ é«˜æ•ˆçš„å®Œæˆå¤æ‚çš„è®¡ç®—éš¾é¢˜ã€‚
>
> â€‹		åœ¨ç›®å‰ä¸»æµä½¿ç”¨çš„**å†¯Â·è¯ºä¾æ›¼ä½“ç³»ç»“æ„**çš„è®¡ç®—æœºä¸­ï¼ŒGPU å±äºä¸€ä¸ªå¤–ç½®è®¾å¤‡ï¼Œå› æ­¤å³ä¾¿åœ¨åˆ©ç”¨ GPU è¿›è¡Œå¹¶è¡Œè®¡ç®—çš„æ—¶å€™ä¹Ÿæ— æ³•è„±ç¦» CPUï¼Œéœ€è¦ä¸ CPU ååŒå·¥ä½œã€‚å› æ­¤å½“æˆ‘ä»¬åœ¨è¯´ GPU å¹¶è¡Œè®¡ç®—æ—¶ï¼Œå…¶å®æŒ‡çš„æ˜¯åŸºäº CPU+GPU çš„å¼‚æ„è®¡ç®—æ¶æ„ã€‚åœ¨å¼‚æ„è®¡ç®—æ¶æ„ä¸­ï¼ŒCPU å’Œ GPU é€šè¿‡ PCI-E æ€»çº¿è¿æ¥åœ¨ä¸€èµ·è¿›è¡ŒååŒå·¥ä½œï¼Œæ‰€ä»¥ CPU æ‰€åœ¨ä½ç½®ç§°ä¸º Hostï¼ŒGPU æ‰€åœ¨ä½ç½®ç§°ä¸º Deviceï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:
>
> ![img](images/0cdb04e0f532229c2c55dd3f07ccf7bc.png)
>
> ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](images/watermark.png)
>
> > GPU ä¸­æœ‰ç€æ›´å¤šçš„è¿ç®—æ ¸å¿ƒï¼Œéå¸¸é€‚åˆæ•°æ®å¹¶è¡Œçš„è®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼Œæ¯”å¦‚å¤§å‹çš„çŸ©é˜µè®¡ç®—ã€‚

**CUDA ç¼–ç¨‹æ¨¡å‹åŸºç¡€**

â€‹		CUDA æ¨¡å‹æ—¶ä¸€ä¸ªå¼‚æ„æ¨¡å‹ï¼Œéœ€è¦ CPU å’Œ GPU ååŒå·¥ä½œï¼Œåœ¨ CUDA ä¸­ä¸€èˆ¬ç”¨ Host æŒ‡ä»£ CPU åŠå…¶å†…å­˜ï¼ŒDevice æŒ‡ä»£ GPU åŠå…¶å†…å­˜ã€‚CUDA ç¨‹åºä¸­æ—¢åŒ…å«åœ¨ Host ä¸Šè¿è¡Œçš„ç¨‹åºï¼Œä¹ŸåŒ…å«åœ¨ Device ä¸Šè¿è¡Œçš„ç¨‹åºï¼Œå¹¶ä¸” Host å’Œ Device ä¹‹é—´å¯ä»¥è¿›è¡Œé€šä¿¡ï¼Œå¦‚è¿›è¡Œæ•°æ®æ‹·è´ç­‰æ“ä½œã€‚ä¸€èˆ¬çš„å°†éœ€è¦ä¸²è¡Œæ‰§è¡Œçš„ç¨‹åºæ”¾åœ¨ Host ä¸Šæ‰§è¡Œï¼Œéœ€è¦å¹¶è¡Œæ‰§è¡Œçš„ç¨‹åºæ”¾åœ¨ Device ä¸Šè¿›è¡Œã€‚

CUDA ç¨‹åºä¸€èˆ¬çš„æ‰§è¡Œæµç¨‹ï¼š

1. åˆ†é… Host å†…å­˜ï¼Œå¹¶è¿›è¡Œæ•°æ®åˆå§‹åŒ–
2. åˆ†é… Device å†…å­˜ï¼Œå¹¶å°† Host ä¸Šçš„æ•°æ®æ‹·è´åˆ° Device ä¸Š
3. è°ƒç”¨ CUDA Kernel åœ¨ Device ä¸Šè¿›è¡Œå¹¶è¡Œè¿ç®—
4. å°†è¿ç®—ç»“æœä» Device ä¸Šæ‹·è´åˆ° Host ä¸Šï¼Œå¹¶é‡Šæ”¾ Device ä¸Šå¯¹åº”çš„å†…å­˜
5. å¹¶è¡Œè¿ç®—ç»“æŸï¼ŒHost å¾—åˆ°è¿ç®—ç»“æœï¼Œé‡Šæ”¾ Host ä¸Šåˆ†é…çš„å†…å­˜ï¼Œç¨‹åºç»“æŸ

> â€‹		CUDA Kernel æŒ‡çš„æ˜¯åœ¨ Device çº¿ç¨‹ä¸Šå¹¶è¡Œæ‰§è¡Œçš„å‡½æ•°ï¼Œåœ¨ç¨‹åºä¸­åˆ©ç”¨ `__global__` ç¬¦å·å£°æ˜ï¼Œåœ¨è°ƒç”¨æ—¶éœ€è¦ç”¨ `<<<grid, block>>>` æ¥æŒ‡å®š Kernel æ‰§è¡Œçš„çº¿ç¨‹æ•°é‡ï¼Œåœ¨ CUDA ä¸­æ¯ä¸€ä¸ªçº¿ç¨‹éƒ½è¦æ‰§è¡Œ Kernel å‡½æ•°ï¼Œå¹¶ä¸”æ¯ä¸ªçº¿ç¨‹ä¼šè¢«åˆ†é…åˆ°ä¸€ä¸ªå”¯ä¸€çš„ Thread IDï¼Œè¿™ä¸ª ID å€¼å¯ä»¥é€šè¿‡ Kernel çš„å†…ç½®å˜é‡ `threadIdx` æ¥è·å¾—ã€‚
>
> ä¸»è¦çš„ä¸‰ä¸ªå‡½æ•°ç±»å‹é™å®šè¯å¦‚ä¸‹ï¼š
>
> - `__global__`ï¼šåœ¨ device ä¸Šæ‰§è¡Œï¼Œä» host ä¸­è°ƒç”¨ï¼ˆä¸€äº›ç‰¹å®šçš„ GPU ä¹Ÿå¯ä»¥ä» device ä¸Šè°ƒç”¨ï¼‰ï¼Œè¿”å›ç±»å‹å¿…é¡»æ˜¯`void`ï¼Œä¸æ”¯æŒå¯å˜å‚æ•°å‚æ•°ï¼Œä¸èƒ½æˆä¸ºç±»æˆå‘˜å‡½æ•°ã€‚æ³¨æ„ç”¨ `__global__` å®šä¹‰çš„ kernel æ˜¯å¼‚æ­¥çš„ï¼Œè¿™æ„å‘³ç€ host ä¸ä¼šç­‰å¾… kernel æ‰§è¡Œå®Œå°±æ‰§è¡Œä¸‹ä¸€æ­¥ã€‚
> - `__device__`ï¼šåœ¨ device ä¸Šæ‰§è¡Œï¼Œå•ä»…å¯ä»¥ä» device ä¸­è°ƒç”¨ï¼Œä¸å¯ä»¥å’Œ`__global__`åŒæ—¶ç”¨ã€‚
> - `__host__`ï¼šåœ¨ host ä¸Šæ‰§è¡Œï¼Œä»…å¯ä»¥ä» host ä¸Šè°ƒç”¨ï¼Œä¸€èˆ¬çœç•¥ä¸å†™ï¼Œä¸å¯ä»¥å’Œ `__global__` åŒæ—¶ç”¨ï¼Œä½†å¯å’Œ`__device__`ï¼Œæ­¤æ—¶å‡½æ•°ä¼šåœ¨ device å’Œ host éƒ½ç¼–è¯‘ã€‚
>
> **Kernel çš„å±‚æ¬¡ç»“æ„**
>
> â€‹		Kernel åœ¨ Device æ‰§è¡Œçš„æ—¶å€™å®é™…ä¸Šæ˜¯å¯åŠ¨å¾ˆå¤šçº¿ç¨‹ï¼Œè¿™äº›çº¿ç¨‹éƒ½æ‰§è¡Œ Kernel è¿™ä¸ªå‡½æ•°ã€‚å…¶ä¸­ï¼Œç”±è¿™ä¸ª Kernel å¯åŠ¨çš„æ‰€æœ‰çº¿ç¨‹ç§°ä¸ºä¸€ä¸ª**ç½‘æ ¼**ï¼ˆ<span style="color:red"> `grid`</span>ï¼‰ï¼ŒåŒä¸€ä¸ª grid ä¸­çš„çº¿ç¨‹å…±äº«ç›¸åŒçš„ `Global memory`ï¼Œgrid æ˜¯çº¿ç¨‹ç»“æ„çš„ç¬¬ä¸€ä¸ªå±‚æ¬¡ã€‚ä¸€ä¸ª grid åˆå¯ä»¥åˆ’åˆ†ä¸ºå¤šä¸ª **çº¿ç¨‹å—**ï¼ˆ<span style="color:red">block</span>ï¼‰ï¼Œæ¯ä¸€ä¸ª block åŒ…å«å¤šä¸ªçº¿ç¨‹ï¼Œå…¶ä¸­çš„æ‰€æœ‰çº¿ç¨‹åˆå…±äº« `Per-block shared memory`ï¼Œblock æ˜¯çº¿ç¨‹ç»“æ„çš„ç¬¬äºŒä¸ªå±‚æ¬¡ã€‚æœ€åï¼Œæ¯ä¸€ä¸ªçº¿ç¨‹ (thread) æœ‰ç€è‡ªå·±çš„ `Per-thread local memory`ã€‚![çº¿ç¨‹ä¸¤å±‚ç»„ç»‡ç»“æ„](images/8e326564c507090fae3b9901f28e817f.png)
>
> <img src="images/209edc7a8ffe54d8591fa753be3a2643.png" alt="å†…å­˜å±‚æ¬¡ç»“æ„" style="zoom: 67%;" />

â€‹		çº¿ç¨‹ä¸¤å±‚ç»„ç»‡ç»“æ„çš„ç¤ºæ„å›¾ï¼Œå…¶ä¸­ grid å’Œ block å‡ä¸º 2-dim çš„çº¿ç¨‹ç»„ç»‡ã€‚grid å’Œ block éƒ½æ˜¯å®šä¹‰ä¸º `dim3` ç±»å‹çš„å˜é‡ï¼Œ`dim3` å¯ä»¥çœ‹æˆæ˜¯åŒ…å«ä¸‰ä¸ªæ— ç¬¦å·æ•´æ•° $(x, y, z)$ æˆå‘˜çš„ç»“æ„ä½“å˜é‡ï¼Œåœ¨å®šä¹‰æ—¶ï¼Œç¼ºçœå€¼åˆå§‹åŒ–ä¸º $1$ã€‚

```c
dim3 grid(3, 2);
dim3 block(5, 3);
kernel<<<grid, block>>>(parameters...);
```

<img src="images/97aff71da70c9be3327c2f2dd28b53ba.png" alt="img" style="zoom:67%;" />

â€‹		ä»çº¿ç¨‹çš„ç»„ç»‡ç»“æ„å¯ä»¥å¾—çŸ¥ï¼Œä¸€ä¸ªçº¿ç¨‹æ˜¯ç”±$(blockIdx, threadIdx)$æ¥å”¯ä¸€æ ‡è¯†çš„ï¼Œ`blockIdx` å’Œ `threadIdx` éƒ½æ˜¯ `dim3` ç±»å‹çš„å˜é‡ï¼Œå…¶ä¸­ `blockIdx` æŒ‡å®šçº¿ç¨‹æ‰€åœ¨ block åœ¨ grid ä¸­çš„ä½ç½®ï¼Œ`threadIdx` æŒ‡å®šçº¿ç¨‹åœ¨ block ä¸­çš„ä½ç½®ï¼Œå¦‚å›¾ä¸­çš„ $Thread(2,1)$ æ»¡è¶³ï¼š

```c
threadIdx.x = 2;
threadIdx.y = 1;
blockIdx.x = 1;
blockIdx.y = 1;
```

â€‹		ä¸€ä¸ª Block æ˜¯æ”¾åœ¨åŒä¸€ä¸ª**æµå¼å¤šå¤„ç†å™¨(SM)**ä¸Šè¿è¡Œçš„ï¼Œä½†æ˜¯å•ä¸ª SM ä¸Šçš„è¿ç®—æ ¸å¿ƒ **(cuda core)** æœ‰é™ï¼Œè¿™å¯¼è‡´çº¿ç¨‹å—ä¸­çš„çº¿ç¨‹æ•°æ˜¯æœ‰é™åˆ¶çš„ï¼Œå› æ­¤åœ¨è®¾ç½® grid å’Œ block çš„ **shape** æ—¶éœ€è¦æ ¹æ®æ‰€ä½¿ç”¨çš„ Device æ¥è®¾è®¡

â€‹		å¦‚æœè¦çŸ¥é“ä¸€ä¸ªçº¿ç¨‹åœ¨ Block ä¸­çš„å…¨å±€ IDï¼Œå°±å¿…é¡»è¦æ ¹æ® Block çš„ç»„ç»‡ç»“æ„æ¥è®¡ç®—ï¼Œå¯¹äºä¸€ä¸ª $2-dim$ çš„ $Block(D_x, D_y)$ï¼Œçº¿ç¨‹$(x, y)$çš„ ID å€¼ä¸º $x + y âˆ— D_x$ï¼Œå¦‚æœæ˜¯ $3-dim$ çš„ $Block(D_x, D_y, D_z)$ï¼Œçº¿ç¨‹$(x, y, z)$ çš„ ID å€¼ä¸º $x + y âˆ— D_x + z âˆ— D_x âˆ— D_y$ ã€‚

ğŸŒ°æ —å­ï¼š**CUDA æŸ¥çœ‹ Device åŸºæœ¬ä¿¡æ¯**

```C
#include <stdio.h>
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
int main()
{
    cudaDeviceProp deviceProp;
    cudaGetDeviceProperties(&deviceProp, 0);
    printf("Device 0 information:\n");
    printf("è®¾å¤‡åç§°ä¸å‹å·: %s\n", deviceProp.name);
    printf("æ˜¾å­˜å¤§å°: %d MB\n", (int)(deviceProp.totalGlobalMem / 1024 / 1024));
    printf("å«æœ‰çš„SMæ•°é‡: %d\n", deviceProp.multiProcessorCount);
    printf("CUDA COREæ•°é‡: %d\n", deviceProp.multiProcessorCount * 64);
    printf("è®¡ç®—èƒ½åŠ›: %d.%d\n", deviceProp.major, deviceProp.minor);
}
// ä»¥ä¸‹æ˜¯æœ¬åœ°ç”µè„‘æ‰§è¡Œç»“æœï¼š
// Device 0 information:
// è®¾å¤‡åç§°ä¸å‹å·: NVIDIA GeForce MX250
// æ˜¾å­˜å¤§å°: 2047 MB
// å«æœ‰çš„SMæ•°é‡: 3
// CUDA COREæ•°é‡: 576
// è®¡ç®—èƒ½åŠ›: 6.1
```

> å…¶ä¸­ç¬¬ 12 è¡Œä¹˜ 64 çš„åŸå› æ˜¯æˆ‘æ‰€ä½¿ç”¨çš„è®¾å¤‡ä¸º MX250ï¼Œè€Œ MX250 ç³»åˆ—å‡é‡‡ç”¨ Pascal æ¶æ„ï¼Œè¯¥æ¶æ„ä¸‹æ¯ä¸ª SM ä¸­çš„ cuda core çš„æ•°é‡ä¸º 64
>
> ğŸŒ°æ —å­ï¼š**CUDA å®ç°å‘é‡åŠ æ³•**
>
> ```C
> // å®ç° Vector Addition
> #include <stdio.h>
> #include <time.h>
> #include <math.h>
> #include "cuda_runtime.h"
> #include "device_launch_parameters.h"
> 
> const int LENGTH = 5e4;
> clock_t start, end;
> void vectorAdditionOnDevice(float*, float*, float*, const int);
> __global__ void additionKernelVersion(float*, float*, float*, const int);
> int main()
> {
>     start = clock();
>     float A[LENGTH], B[LENGTH], C[LENGTH] = {0};
>     for (int i = 0; i < LENGTH; i ++) A[i] = 6, B[i] = 5;
>     vectorAdditionOnDevice(A, B, C, LENGTH);  //calculation on GPU
>     end = clock();
>     printf("Calculation on GPU version1 use %.8f seconds.\n", (float)(end - start) / CLOCKS_PER_SEC);
> }
> void vectorAdditionOnDevice(float* A, float* B, float* C, const int size)
> {
>     float* device_A = NULL;
>     float* device_B = NULL;
>     float* device_C = NULL;
>     cudaMalloc((void**)&device_A, sizeof(float) * size);  // åˆ†é…å†…å­˜
>     cudaMalloc((void**)&device_B, sizeof(float) * size);  // åˆ†é…å†…å­˜
>     cudaMalloc((void**)&device_C, sizeof(float) * size);  // åˆ†é…å†…å­˜
>     const float perBlockThreads = 192.0;
>     cudaMemcpy(device_A, A, sizeof(float) * size, cudaMemcpyHostToDevice);  // å°†æ•°æ®ä» Host æ‹·è´åˆ° Device
>     cudaMemcpy(device_B, B, sizeof(float) * size, cudaMemcpyHostToDevice);  // å°†æ•°æ®ä» Host æ‹·è´åˆ° Device
>     additionKernelVersion<<<ceil(size / perBlockThreads), perBlockThreads>>>(device_A, device_B, device_C, size);  // è°ƒç”¨ Kernel è¿›è¡Œå¹¶è¡Œè®¡ç®—
>     cudaDeviceSynchronize();
>     cudaMemcpy(device_C, C, sizeof(float) * size, cudaMemcpyDeviceToHost);  // å°†æ•°æ®ä» Device æ‹·è´åˆ° Host
>     cudaFree(device_A);  // é‡Šæ”¾å†…å­˜
>     cudaFree(device_B);  // é‡Šæ”¾å†…å­˜
>     cudaFree(device_C);  // é‡Šæ”¾å†…å­˜
> }
> __global__ void additionKernelVersion(float* A, float* B, float* C, const int size)
> {
>     // æ­¤å¤„å®šä¹‰ç”¨äºå‘é‡åŠ æ³•çš„ Kernel
>     int i = blockIdx.x * blockDim.x + threadIdx.x;
>     C[i] = A[i] + B[i];
> }
> ```



### å¹¶è¡Œçº¿ç¨‹ç»„ç»‡ç»“æ„

Threadï¼šå¹¶è¡Œçš„åŸºæœ¬å•ä½

Thread blockï¼šäº’ç›¸åˆä½œçš„çº¿ç¨‹ç»„

- Cooperative Thread Array (CTA)
- å…è®¸å½¼æ­¤åŒæ­¥
- é€šè¿‡å¿«é€Ÿå…±äº«å†…å­˜äº¤æ¢æ•°æ®
- ä»¥1ç»´ã€2ç»´æˆ–3ç»´ç»„ç»‡
- æœ€å¤šåŒ…å«512ä¸ªçº¿ç¨‹

Gridï¼šä¸€ç»„thread block

- ä»¥1ç»´ã€2ç»´æˆ–3ç»´ç»„ç»‡
- å…±äº«å…¨å±€å†…å­˜

Kernelï¼šåœ¨GPUä¸Šæ‰§è¡Œçš„æ ¸å¿ƒç¨‹åº

<img src="images/image-20230430181637062.png" alt="image-20230430181637062" style="zoom:67%;" />

> <img src="images/image-20230430181710045.png" alt="image-20230430181710045" style="zoom:50%;" />





## ç¼–ç¨‹



### CUDAå¼•å…¥çš„æ–°å˜é‡

- `__device__`
  - å‚¨å­˜äºGPUä¸Šçš„global memoryç©ºé—´
  - å’Œåº”ç”¨ç¨‹åºå…·æœ‰ç›¸åŒçš„ç”Ÿå‘½æœŸ(lifetime)
  - å¯è¢«gridä¸­æ‰€æœ‰çº¿ç¨‹å­˜å–,CPUä»£ç é€šè¿‡`runtime`å‡½æ•°å­˜å–
  
- `__constant__`
  - å‚¨å­˜äºGPUä¸Šçš„`constant_memory`ç©ºé—´
  - å’Œåº”ç”¨ç¨‹åºå…·æœ‰ç›¸åŒçš„ç”Ÿå‘½æœŸ(lifetime)
  - å¯è¢«gridä¸­æ‰€æœ‰çº¿ç¨‹å­˜å–,CPUä»£ç é€šè¿‡runtimeå‡½æ•°å­˜å–
  
- `___shared__`
  - å‚¨å­˜äºGPUä¸Š`thread block`å†…çš„å…±äº«å­˜å‚¨å™¨
  - å’Œ`thread block`å…·æœ‰ç›¸åŒçš„ç”Ÿå‘½æœŸ(lifetime)
  - åªèƒ½è¢«thread blockå†…çš„çº¿ç¨‹å­˜å–
- `Localå˜é‡`
  - å‚¨å­˜äºSMå†…çš„å¯„å­˜å™¨å’Œ`local memory`
  - å’Œthreadå…·æœ‰ç›¸åŒçš„ç”Ÿå‘½æœŸ(lifetime)
  - Threadç§æœ‰



### å‡½æ•°å®šä¹‰

|                                  | Exexuted on the | Only callable from the |
| :------------------------------: | :-------------: | :--------------------: |
| `__device__ ` float DeviceFunc() |     deivce      |         deivce         |
|  `__global__` void KernalFunc()  |     deivce      |          host          |
|   `__host__` float HostFunc()    |      host       |          host          |

> `__global__` å®šä¹‰ kernal å‡½æ•° å¿…é¡»è¿”å› void
>
> `__device__` å’Œ `__host__` å¯ä»¥ç»„åˆä½¿ç”¨ï¼Œéƒ½å¯åœ¨ CPUä¸GPU ä¸Šè¢«ç¼–è¯‘

> â€‹		**SMæ˜¯æŒ‡æµå¤šå¤„ç†å™¨**ï¼ˆStreaming Multiprocessorï¼‰çš„ç¼©å†™ã€‚SMæ˜¯ä¸€ç§ä¸“é—¨ä¸ºGPUè®¾è®¡çš„å¤„ç†å™¨ï¼Œæ¯ä¸ªSMéƒ½åŒ…å«å¤šä¸ªCUDAæ ¸å¿ƒï¼Œèƒ½å¤ŸåŒæ—¶æ‰§è¡Œå¤šä¸ªçº¿ç¨‹ã€‚æ¯ä¸ªSMéƒ½æœ‰è‡ªå·±çš„å¯„å­˜å™¨ã€å…±äº«å†…å­˜å’Œé«˜é€Ÿç¼“å­˜ï¼Œå¯ä»¥ç‹¬ç«‹åœ°æ‰§è¡ŒæŒ‡ä»¤ï¼Œå› æ­¤å¯ä»¥å¹¶è¡Œæ‰§è¡Œå¤šä¸ªçº¿ç¨‹å—ã€‚çº¿ç¨‹å—æ˜¯ä¸€ç»„çº¿ç¨‹çš„é›†åˆï¼Œå¯ä»¥åœ¨ä¸€ä¸ªSMä¸Šæ‰§è¡Œã€‚å½“çº¿ç¨‹å—è¢«åˆ†é…åˆ°SMä¸Šæ—¶ï¼ŒSMå°†ä¸ºçº¿ç¨‹å—ä¸­çš„æ¯ä¸ªçº¿ç¨‹åˆ†é…å¯„å­˜å™¨ã€å…±äº«å†…å­˜å’Œé«˜é€Ÿç¼“å­˜ï¼Œå¹¶æ‰§è¡Œçº¿ç¨‹å—ä¸­çš„æŒ‡ä»¤ã€‚é€šè¿‡å°†çº¿ç¨‹å—åˆ†é…åˆ°ä¸åŒçš„SMä¸Šæ‰§è¡Œ
>
> <img src="images/image-20230430182551699.png" alt="image-20230430182551699" style="zoom:50%;" />



## FAQ

1. VS 2022  ç”Ÿæˆä¾èµ–é¡¹â†’ ç”Ÿæˆè‡ªå®šä¹‰â†’ æ²¡æœ‰CUDA 

```shell
# å°†ä»¥ä¸‹ç›®å½•ä¸­çš„ æ–‡ä»¶æ‹·è´
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\extras\visual_studio_integration\MSBuildExtensions

# è¿™ä¸ªç›®å½•ä¸­
E:\Visual Studio\MSBuild\Microsoft\VC\v170\BuildCustomizations
```

2. VS 2022  æ–°å»ºé¡¹ç›®é‡Œæ²¡æœ‰ CUDA æ¨¡æ¿é€‰é¡¹

```shell
# æ­¤ç›®å½•ä¸‹è¿è¡Œä»¥ä»£ç 
E:\Visual Studio\Common7\IDE\Extensions

mkdir NVIDIA
cd NVIDIA
mkdir CUDA 11.8 Wizards
cd CUDA 11.8 Wizards
# mkdir 11.8
# cd 11.8

# å°†ä»¥ä¸‹ç›®å½•ä¸­çš„ extension.vsixmanifest ä¸ Nvda.Vsip.CudaTemplates.pkgdef åˆ›å»ºå¿«æ·æ–¹å¼
C:\ProgramData\NVIDIA GPU Computing Toolkit\v11.8\extras\visual_studio_integration\CudaProjectVsWizards\17

# Final æ‰“å¼€ Developer Command Prompt for VS 2022(å¼€å‘è€…å‘½ä»¤æ§åˆ¶å°) å¹¶è¿è¡Œ
devenv.com /setup /nosetupvstemplates

# ä¸Šè¿°æ–¹æ³•æ— æ•ˆï¼Œä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼
mklink /d "E:\Visual Studio\Common7\IDE\Extensions\NVIDIA\CUDA 11.8 Wizards\11.8" "C:\ProgramData\NVIDIA GPU Computing Toolkit\v11.8\extras\visual_studio_integration\CudaProjectVsWizards\17"

# ç®¡ç†å‘˜èº«ä»½æ‰“å¼€è¿è¡Œ (IDE)
devenv /updateconfiguration
```

3. æµ‹è¯•ç¨‹åº CUDA æ˜¯å¦å®‰è£…æ­£ç¡®ï¼

```shell
# æµ‹è¯•ç¨‹åºé»˜è®¤åœ¨ æ­¤ç›®å½•
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8\extras\demo_suite
```

```shell
[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: NVIDIA GeForce MX250
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(MB/s)
   33554432                     3014.8

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(MB/s)
   33554432                     3090.9

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(MB/s)
   33554432                     47426.0

Result = PASS
```

```shell
deviceQuery.exe Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "NVIDIA GeForce MX250"
  CUDA Driver Version / Runtime Version          11.8 / 11.8
  CUDA Capability Major/Minor version number:    6.1
  Total amount of global memory:                 2048 MBytes (2147352576 bytes)
  ( 3) Multiprocessors, (128) CUDA Cores/MP:     384 CUDA Cores
  GPU Max Clock rate:                            1582 MHz (1.58 GHz)
  Memory Clock rate:                             3504 Mhz
  Memory Bus Width:                              64-bit
  L2 Cache Size:                                 524288 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               zu bytes
  Total amount of shared memory per block:       zu bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          zu bytes
  Texture alignment:                             zu bytes
  Concurrent copy and kernel execution:          Yes with 5 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)
  Device supports Unified Addressing (UVA):      Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 2 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.8, CUDA Runtime Version = 11.8, NumDevs = 1, Device0 = NVIDIA GeForce MX250
Result = PASS
```

